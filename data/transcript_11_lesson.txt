 Просто достаточно докера, сегодня мы с видеокартой ничего делать не будем, просто нужно, чтобы у вас на компьютере был установлен докер. У нас сегодня будет такая, типа, наполовину лекция, наполовину практические, ну, больше практические, потому что про докер я буду рассказывать, типа, по ходу дела, и будем выполнять задания. И посмотрим, типа, как можно с ним работать. А вы докер будете с нуля объяснять, да? Потому что я, например, не сталкивался с этой программой. Не то чтобы с нуля, а более такой, проведу некий ликбез, и потом уже практически перейдем. Ну, я объясню, что это, как с ним работать, и, надеюсь, за два часа мы управимся. Ну, я, например, не знаю, как вы думаете, что докер вымечаем? Потому что я вот недавно на один из проектов мы выбирали между докерами, и еще услышали про подмен, который работает без деймона. Да, я, к сожалению, подменом не пользовался. Есть еще альтернатива ContainerD. За последние два года докер чуток начал сдавать позиции, по этой причине. Ну, это из-за того, что Kubernetes, это я потом расскажу, он начал, условно, форсить в ту сторону, чтобы вместо докера использовать ContainerD, по этой причине и альтернативы помимо докера начали лучше расти, чем остальные, можно так сказать. Но принцип у них примерно одинаков. Они также занимаются контейнеризацией приложения, некой виртуализацией. И это просто одна из альтернатив. Просто докер, он есть везде, и он везде используется, и по этой причине. Просто, условно, по популярности подмен не так сильно стоит на том уровне, как докер, можно так сказать. Хорошо, спасибо. Ну что, ребят, начнем? Так, в принципе, это не нужно. Докер включен. Ну, я, конечно, не хочу, что бы вы не поняли, но я, конечно, не хочу, что бы вы не поняли, что это такое. Так, в принципе, это не нужно. Докер включен. Еще один вопрос. Вы же все видели, да, контент лекции, типа, все, что сейчас мы будем делать, оно находится в этом. Уже в Google Classroom, типа, оттуда все, что вы можете, все скачать. Так, сейчас мне еще будет вот это. Клёвс. Окей. Извиняюсь. Да, да. Извиняюсь, я сейчас поздно дома, только-только прихожу. Я хотел знать, о чем главная особенность докера. Я понимаю, контейнеризация меньше места занимает на комплектации. А в чем, ну, преимущество докера, самое главное, если можно просто на компьютере запускать либо на докере. Ну, имеется в виду, что вы сами только что ответили на вопрос. Его главное отличие от виртуальной машины, это, конечно, что он не работает. Но, конечно, в принципе, это не просто, что он работает. Ответили на вопрос. Его главное отличие от виртуальной машины в том, что он, типа, более облегченный. И, наверное, самое ключевое отличие от виртуальной машины докера, точнее, докеры от виртуальной машины, то, что ядро, которое используется, условно, у каждого компьютера, ну, типа, у каждой операционной системы есть ядро. И виртуальная машина, оно не использует, типа, то ядро, которое используется на хосте, условно, на машине, в которой она поднимается. Оно создает свое собственное ядро. По этой причине оно больше ресурсов пушит. А докер, условно, он использует, ну, типа, хостовая система шерит вместе с докером, условно, свой кернал. Ну, это ядро. Ядро это как раз, типа, условно, ваша операционная система, которая, условно, есть, так сказать, я понял. Да, вот так можно сказать. Так, ребята, давайте начнем. Сейчас я зашарю экран и начнем лекцию. К этой лекции с Linux состоит быкация или можно с Windows зайти? Если, так, ребята, у кого Mac и Linux у вас, в принципе, с докером проблем, ну, не то что проблем, там очень легкая установка, а тех, у кого Windows, вам, к сожалению, нужно будет там покопаться чуть-чуть с Windows Subsystem Linux, это VSL, и через него докер поставить. Ну, в принципе, там проблем, если вы ставите просто, типа, докер, то, я думаю, проблем не должно быть. Там очень много, если вбить в Google, то первое обычно, как установить докер на Windows, он там прямо хорошо скажет, потому что как раз-таки Windows Subsystem Linux, ну, типа, Linux под Windows, он очень сильно облегчает работу. Я сейчас одну минутку, ребята. Роль какой там выбирать, не подскажете? Там Student Teacher, Full Stack стоит там, короче, Datasentist и так далее. Без разницы там, не сильно важно вообще. А, да? Да. Так, одну минуту, ребятки. Так, шарим экран. Да, docker.docs.docs.com.gile, это нормальный сайт, это официальный сайт Docker. Так, шарим экран. Advanced, advanced test. Так, шарим экран. Так, шарим экран. Так, шарим экран. Шарим экран. Advanced, advanced test. Сейчас шир. Вы сейчас видите мой экран, да, если я ошибаюсь? Да, да, видно. Так, в принципе, так начнем. Сегодня мы поговорим о докере, о его особенностях, о контейнеризации, в принципе, о том, как работать с приложениями, как их оборачивать и вообще все, что с этим связано. Так, перед тем, как начнем, я хотел вас спросить, у вас есть общее понимание, как работать с данными, как обучать модели, как работать со скейлингом, как работать, в общем, со всеми этими вопросами, именно как правильно делать evaluation модели и prediction. С этим вопросов нет, да? Ну, вроде да. Да, это прошли. Окей, хорошо, классно, тогда можно дальше продолжать. Сегодня мы поговорим про Docker, про его основные команды, про Docker files, потом еще чуть-чуть я объясню, именно как он в AI-инжиниринге используется. Поговорим также про Docker Compose, про multistage Docker и вообще про CACD и чуть-чуть про advanced subtopics, и на этом вопросами и ответами закончим урок. Так, перед тем, как условно начнем рассказывать про Docker, давайте поговорим о том, что как вообще до этого условно запускались там программы. Все это происходило за счет того, что условно в серверах стояла основная хостовая система, некий HyperWinner, можем его так называть. Это та программа, которая управляла виртуальными машинами. Представьте, у вас огромные сервера, на них стоит огромное количество приложений. До того, как Docker был изобретен, до него использовалась виртуальная машина. Представьте, что у вас для каждого вашего приложения, чтобы они условно с друг другом как-то не конфликтовали, вы поднимали виртуальную машину. Виртуальная машина – это условно некая обрезанная операционная система, которая может запуститься на вашем компьютере. Для этого можно использовать приложение VirtualBox, GameWare и так далее. Но в качестве примера представим, что у вас есть ваша операционная система. Вот как можем здесь заметить, ваш сервер, видно, да, паемышка? Ребят, вот здесь. Ну да, она очень мелкая у вас. Да, видно, но мелкая. На, sorry. Представим, что у нас есть сервер, потом есть хастовая система. Представим, что это наш Windows, MacOS, без разницы. И есть Hypervisor. Это как раз таки условно некий управленец, некая там программа, которая позволяет вам создавать вашу виртуальную машину, в которой будет операционная система, будут свои библиотеки и будет приложение, которое будет запускаться. Давайте представим это на примере сайта, на который вы запускаете условно до того, как Docker появился. В серверах создавалась определенная виртуальная машина, на которой условно условно билдился сайт. А в другой операционной системе, точнее, во второй виртуальной машине создавалась база данных. Ну это в качестве примера. И так они коммуницировали с друг другом внутри огромного сервера. И это приводило к определенным неудобствам. И люди пришли к тому, что создали Docker. И чем же Docker отличается? Самый основной способ, который мы получили, это был сайт. Самый основной момент, это то, что в вашем сервере, в вашей операционной системе вы используете определенный Engine, который позволит вам без создания отдельной виртуальной машины, отдельной операционной системы, вы просто берете и выделяете область в вашем компьютере под определенные инструкции. Условно под Docker какой-то контейнер. И вот как вообще весь этот процесс построен. У вас есть некий Docker File, как показано на этом изображении. Это мы. У нас есть несколько команд. Это Docker Build, Run, Pull, Push. Я дальше объясню, что это за команды. И условно это некий клиент, за счет которого, используя инструкции, показанные в Docker File, мы можем создавать наш контейнер. Точнее, сначала наш образ и контейнер. Как это происходит? У нас есть Docker Host. Это как раз наш Docker Engine, который позволяет нам за счет Docker File определенных инструкций сделать сначала image. Image – это образ, а контейнер – это контейнер. Image – это условно некая программа, созданная под инструкцией Docker File, с определенными командами, которые нужно будет выполнить. Потом условно под эти инструкции мы хотим создать контейнер, где мы запустим уже эту условно маленькую мини-операционную систему. Но это не будет операционную систему. Это будет какая-то изолированная часть нашей системы, которая будет контейнером. В качестве примера мы можем привести то, что у нас есть… Всем этим управляет Docker Demon, а Volumes – это те части вашей… условно это части системы, которые вы можете делиться с вашим Docker Container. Условно если вы просто запускаете Docker Container, он запускается у вас на компьютере, и происходит такой момент, что условно вы хотите… Типа ваша операционная система хочет шерить с ним какой-то диск. Условно чтобы это все происходило… Это все происходило… Типа вы могли менять файлы условно в этом Volumes, и это может происходить изнутри контейнера. В принципе, это все по основам. По командам Docker Build это вы создаете образ. Docker Run вы запускаете контейнер на основе вашего образа. Docker Pull – это условно… Есть Registry – это скажем так некое хранилище, которое может хранить в себе как раз-таки эти образы. И у нас есть возможность запулить, взять себе из этого Registry. Registry может быть общим, доступным до всего мира, и может быть локальным для какой-то определенной компании, команды, без разницы. Вы можете взять оттуда уже готовые образы, сделанные под определенные программы, просто можете сделать Pull для себя и сделать Run. Вам Build-ить не обязательно, потому что уже кто-то за вас создал некий образ, который точно будет работать на вашем компьютере, вам не нужно париться с библиотеками, и вы можете просто подгрузить, запустить вашу программу, и все, на этом вопрос решится. Docker Push – это уже когда вы создали контейн-образ на основе вашего Docker файла, и вы можете сделать Push в Registry. Здесь самый основной момент – зачем вообще используется Docker? Представьте, что вы какой-то разработчик, у вас стоит определенная операционная система, и вы делаете какой-то проект. Представим, что Docker нет. Вы под вашу операционную систему запарились, подгрузили огромное количество библиотек, сделали очень много Build-ов, и прям с горем пополам как-то запустили и создали эту библиотеку. Потом вы пишете код, который как раз к этой библиотеке используют, и у вас все отлично работает. Вы разработчик. Но давайте теперь перейдем к тому, чтобы перейти из этапа разработки на этап уже от продакшена. В этот момент у вас уже появляется вопрос. Вам нужно будет все действия, которые вы делали у вас на компьютере, делать уже на продакшене, уже нужно будет там париться над неким… типа Compatibility, чтобы именно была некая взаимосвязь, и чтобы все правильно работало, чтобы все… Ваша программа использовала как раз те библиотеки, на которых вы создавали, потому что, условно, ваша программа работает на какой-то библиотеке 10-й, условно NumPy, представим, NumPy 10-й какой-то. Но нечаянно вы на продакшене установили NumPy 20-й, и они очень сильно от друг друга разнятся, у вас вот рушатся, и приходится как-то выкручиваться и обратно все это типа переустанавливать, переобилдивать и заниматься очень ненужным таким обезьяньим трудом. И как раз-таки здесь появляется Docker, который как раз-таки, условно, вы создали у себя внутри определенную инструкцию, создали образ, который точно будет у вас работать, и просто делаете его push в Docker Registry, и когда это идет на продакшен, оно просто pull-ится как раз в Registry, запускается, и там в 99 случаях из 100 оно запустится. В общем, чем его роль в современной разработке? Это как раз-таки зависимости, о которых мы только что разговаривали, о том, что зависимости вашего приложения, вашего кода, да вообще без разницы, даже ваша база данных может быть, у нее могут быть определенные зависимости, и оно может просто не заработать. И самое, какой боль очень сильно решает как раз-таки Docker, это у меня работает, условно, там у одного разработчика код запустился, и его программа забилдилась, все нормально, но не работает у его товарища, который сидит рядом, который практически делает то же самое, но просто он мог пропустить одну какую-то черточку, либо просто забыл указать в нужном месте, там нужно какой-то определенный файл. И еще решает проблему развертывая вместе, то, что можно будет условно, наше приложение, оно может работать условно на 10 тредах, но сервис огромный, мы можем попробовать развернуть на огромных 100-200 потоках, без разницы, все зависит от наших возможностей и нашего сервера. И дальше самое основное вопрос, это унификация, то, что мы, типа Docker позволяет нам унифицировать и упрощать разработки сотни команд. Представьте, что вам нужно будет, условно, в вашей компании есть 20 команд, ну, вам это слишком много, ну, пишем, 5 команд, там, фронтендеры, байкендеры, девопсеры, там, ML-щики и бизнес-аналитики. И каждый из них использует какую-то часть огромного софта, но у кого-то, какие-то ребята, условно, какая-то команда решила добавить определенную там, библиотеку или какой-то новый плагин, им не нужно париться, что у тех ребят не запустится или там что-то им нужно установить, у них есть определенный стандарт, по которому они могут это сделать, и другие ребята тоже подтянут, и у них там тоже не возникнет никаких проблем, и у всех будет определенный унифицированный формат, ну, универсальность, можно так сказать. Так, дальше, вопросы есть здесь, ребят? Все понятно? Или есть какие-то вопросы? Ребят? Можно вопрос, да? Да, конечно, да. А вот как именно Docker это все решать? То есть dependency с первой и другие пункты? Dependency именно, условно, я сейчас по ходу дела, когда мы будем работать в практике, более подробнее объясню, но если так сказать, представьте, что у вас есть приложение, которое запускается в каком-то контейнере, и представим, что какой-то разработчик, когда не было всех этих пяти команд, создал этот контейнер за счет определенного Docker файла, определенных команд, он создал все зависимости, и он уже заранее указал все эти зависимости, и все остальные команды могут просто взять этот образ и запускать у себя, и у них не будет проблем зависимости. И еще один важный момент, то что если какая-то из этих команд, условно, сделать изменение в этом образе, то у всех это изменение потянется, и им не нужно будет париться насчет зависимости, типа они могут сделать еще раз build, и у них забилдятся. Как раз у всех то, что они работают условно в одной и той же среде, им уже среда разработки, в которой находятся их приложения, команды или программы, она уже не уходит на второй план, потому что оно у всех одинаково, и вам не нужно будет париться над тем, что у тех ребят из другой команды у них не запустится. Я надеюсь, ответил на ваш вопрос, да? Да, да, понял. Окей, хорошо. Извини, я вот чисто, чтобы подтвердить, правильно ли я все понял, то есть есть, например, у нас команда, там бэкендеры есть, фронтендеры, там мл-чики, да, и еще кто-то. Каждый работает в своей среде разработки, соответственно, каждый бэкендер делает свою, ну, там каждая команда делает свой, контейнеризацию своей среды разработки, да? Соответственно, чтобы это все вместе работало, там они все вот эти контейнеры складывают и там выпускают в приложении или в сайт какой-нибудь, или еще что-то в том роде, да? Да, у них есть несколько вариантов. Они могут все это делать в отдельных контейнерах, типа их приложения могут общаться, да? Или они могут делать, условно, все объединять в один контейнер, чтобы это было условно монолитным приложением, и типа так же тоже работать. Там не обязательно, чтобы они делились друг другом, у них условно среда разработки, она будет унифицирована, приведена к одному формату, чтобы они были... чтобы не было там каких-то проблем у какой-то из этих команд. Понятно, да? Да-да, понятно, все предельно, спасибо. Окей, хорошо, давайте продолжаем. Сейчас мы поговорим о том, как правильно создавать Docker файлы, что такое cache в Docker файле, как работают слои, и еще... почему пятая? По ходу, автоматически появилась, окей. И как работает multistage Docker, Docker build. Так, в принципе, можно переходить на practical lesson. Так, час, видно, печально, да? Очень мало. Так нормально видно, ребят? Да, нормально. Окей, хорошо. В принципе, здесь я добавил заранее людьми, и если что, типа если у вас будет... Это для ребят, которые не присутствовали, для них, для них, так условно, есть, типа, некая ремарка, что зачем запускали. Окей, давайте представим ситуацию. Пока я уберу терминал, он мне не нужен. Я сейчас хочу создать приложение. Сначала я вам покажу код. Это очень там простой код, который... что он делает? Он условно подгружает какой-то data set. Это iris, это, если не ошибаюсь, кажется, цветочки, да? Да, это датасет цветочков. Он там делает train-to-split, разделяет данные. Мы здесь не паримся насчет модели. Нам важно попробовать с ней поработать. Насчет ее качества, может, не переживать. Мы создаем pipeline, который сначала скейли данные, как-то он у себя внутри закрывает вопрос, как называется, чтобы все данные были в одном числовом значении, типа в числовом интервале. Запускаем support-вектор кодом Classifier, делаем fit, типа тренируем нашу модель, делаем предсказания на каком-то нашем тестовом датасете, пробегаемся по classification report. Classification report – это built-in функция внутри Skykit Learn, которая позволяет сделать репорт насчет точности вашей модели. Это очень простая функция. Я вам покажу результат. Потом мы принтуем точность нашей модели. И в конце, для прикола, мы возьмем какой-то супер простой сэмпл и попробуем сделать предикт. Перед тем, как я сейчас начну работать с докером, есть ли у вас вопросы относительно этого кода? Он предельно простой, и вы, скорее всего, все это делали уже. Все правильно, да? Я просто не хочу, чтобы вы дальше задавали вопросы насчет модели, потому что нам она сейчас не важна, она играет рассортную роль. Нам сейчас важно попробовать с ней поработать на основе докера. Ребят? Да, вроде бы. Да, тут все нормально. Окей, хорошо. Так, так, так. Почему? Окей, хорошо. Тогда мы забиваем на него. У нас есть docker-файл. Что он делает? Здесь... Это наш docker-файл. Это наша инструкция, которая позволяет нам создать наш образ на основе этой программы. Что для нас здесь слои? У докера есть слои. Условно, будем считать... Это не за слои. Здесь вы создали... Условно до этого workDir'а мы сейчас подгрузили какой-то docker-image, docker-образ, который называется Python 3.9 slim. Это образ, в котором уже предустановлен Python 3.9. Нам насчет этого париться не надо. Slim – это, если не ошибаюсь, суперуреженная версия. Затем мы внутри него обозначаем, что нашей рабочей следой будет... Точнее, рабочей папкой внутри нашей операционной системы будет папка app. Потом это уже, словно, слой номер один. Layer number one. Кажется, есть... Нет, все-все правильно. Layer number one. Я не уверен, насчет environment, скорее всего, это не является... Хотя, не, условно, это типа слой номер два. Хотя нет, если не ошибаюсь, environment не является слоем. Но в принципе, пока давайте упустим этот момент. Потом дальше у нас, в этой директории, где сейчас запускается наш docker-файл, с левым... Всем видно, да? Ребят? Да, да видно. Это наша рабочая папка, практика lesson1, в которой у нас есть docker-файл, main.py и наш requirement.txt. Здесь всего лишь там две библиотеки, skykit-learn и numpy. Нам только они и нужны. Что мы делаем? Мы берем, копируем наш requirement.txt, наш requirement.txt внутрь докера. Это наш слой номер три. Layer номер три. И да, в принципе, layer. Потом мы запускаем команду... Layer номер четыре. Мы запускаем команду... Все. Мы запускаем команду pip install – new cache dir – R requirement.txt. Почему мы в него указали? По той причине, потому что мы уже заранее скопировали наш requirement.txt внутрь нашего образа, и он уже как представлен requirement.txt. Но у нас есть возможность его переименовать, таким образом назовем rec.txt. И уже здесь мы можем rec.txt. Это сделано по той причине, потому что это команда, копии, это название сорса, это название вашего destination. И в этом случае наша команда pip установит библиотеки с той папкой, которую мы скопировали с хастовой системы внутрь нашего образа. И дальше мы копируем наш копии main.py опять же в нашу рабочую директорию. Все это, кстати, происходит в папке app. И потом в конце наш Docker образ он запустит python.main.py. Но в чем прикол? Во время билда, когда мы будем делать именно Docker build, когда мы будем готовить наш образ, все эти команды запустятся, но вот эта последняя команда не запустится. Она будет ждать момента, когда мы сделаем условно run. Так, давайте теперь попробуем поработать с Docker File. Первым делом мы должны сделать build. Как это будет происходить? Условно... Всем нормально видно, да? Сейчас кажется, он прям очень огромный. Давайте сделаем так. Программа будет происходить таким образом. Мы делаем Docker build. Minus t – это название вашего образа, который вы хотите назвать. Условно назовем его... Условно там iris-model-1.0. Это некие... Условно мы так назвали. Давайте покатую берем. У нас есть возможность указать... Если мы сделаем просто точка, типа именно в этой папке, он возьмет файл, который будет в этой папке. Но я хочу вас заранее научить, чтобы вы всегда указывали minus f, ваш Docker File, и нужно указать точку. Build его здесь обязательно. Есть у вас вопросы по поводу выполнения команды. Мы вызываем наш программу Docker, говорим ему сделать команду build, назови образ, который ты сейчас будешь building, и он будет в этой папке. Назови образ, который ты сейчас будешь building, iris-model-1.0, и на основе файла инструкция, которая сделана в Docker File, которая условно здесь рядом стоит, и точка. Если мы сейчас сделаем, он начнет building. И все, началось. То есть это команда для создания контейнеризации? Мы не создаем контейнер, мы создаем образ. Мы создаем образ. Значит, не будет? Это значит у нас... Можете поднять команду? Увидите еще. Проверим на простынь. Сейчас одну минуту. Спросите. Все. И значит еще один. У меня номера. А у вас все это же есть, если не ошибаюсь? Или нет? Ребят? А где я... Не, скачали все файлы, а команды где можно увидеть? У меня там прикреплена все. Зипка. Вы про какие команды спрашиваете? Консоли. Ааа. Команда вот. Ребят, давайте теперь посмотрим очень внимательно. Кстати, все команды, которые я буду выполнять в терминале, они в makefile указаны. Как делать build, как делать run. С очень разными весями. Это все уже указано. Я сейчас хотел очень объяснить, пока это не про... Блин, оно... Да, вот. Теперь смотрите. Если не ошибаюсь у всех, если вы установите последний Docker, то можно будет заметить вот такие, типа 2 из 5, 3 из 5, 4 из 5, 5 из 5. Это как раз-таки ваши слои. Первый слой — это как раз-таки, когда вы берете, словно в самом начале мы делаем from. Это когда мы полностью скачали вот этот уже там base образ. Это слой номер один. Мы создали... Докеры состоят из вот таких слоев, которые закешированы. Потом дальше идет слой номер два, который называется workdirup. Вы сделали какую-то определенную команду — workdirup. И у вас это сохранилось в каком-то определенном... Как бы сказать... В неком слое. Потом дальше происходит copy. Requirements.txt — это слой номер три, как мы здесь с вами указали. Когда вы называете environment, это не считается за слой. Потом... Команда copy — это слой номер три. Команда run — это четвертый слой из пяти. И последняя наша команда — copy mainpy. И как я вам говорил, что наш последний layer, точнее, cmd, это не является слоем. По той причине потому, что это команда, которая будет выполняться, когда этот образ превратится в контейнер. Когда вы будете запускать ваш контейнер на основе этого образа, тогда в этом случае это команда cmd. Но команда, оно выполнится. Сейчас по поводу создания docker образа. У вас вопросы есть, ребята? Или что мы сделали? Или нет? Можно спросить не по поводу создания, а сколько это по имени примерно занимает создание самого образа? Просто когда я создавал раньше, у меня очень долго оно ранило. Все очень по-разному. Но мы можем сейчас проверить. Есть команда docker images. Сейчас наш образ весит 428 мегабайт. Спасибо. Там бывают разные docker. Docker images некоторые могут весить до 20-30 гигабайт, что очень плохо. Продолжаем дальше. Что мы сейчас сделали? Мы создали образ. Если сейчас заметим... Нет. Clear. Docker images. Сейчас у нас в нашей директории есть уже готовый образ. Называется iris-модель. У него есть tag 1.0. Это его image ID. Это ID-шник нашего docker. Насчет него можете не обращать внимания. Это условно некий идентификатор вашего образа в вашей операционной системе. У него есть size. Он весит 428 мегабайт. Теперь наша задача с вами запустить этот docker. Запускается это таким образом. У нас есть команда docker run iris-model 1.0. И теперь смотрите, ребята. Когда мы сделали docker run... Когда мы... Так. Сначала... Нет. Кажется, не будет так правильно. Docker run iris-model 1.0. Смотрите. Вы помните, что мы сделали с вами? Мы с вами сделали нашу команду, которая загрузила данные с датасета iris. Взяла там seed-42 условно. Обучила модель. Сделала feed predict, в котором она показала пресижен, recall, f1-score и все остальное. И наша точность моделя 1.0, что на это можете не обращать внимания. И в самом конце предсказания класса. И что мы сейчас видим? У нас сейчас этот контейнер. Есть такая команда docker ps-a, в которой вы можете заметить все запущенные ваши docker контейнеры. Сейчас мы с вами сделали docker run два раза. Docker run два раза. И наш образ запустился два раза. Создался контейнер на основании его. Можно смотреть, что у него status exited. Потому что команда закончила выполнять свою команду. И по этой причине она exited. И это та, которую мы недавно запустили. Это та, которую мы раньше запустили. И теперь мы можем проверить его логи. Это docker logs-f. И как мы заметили, все, что мы выполнили. Мы сделали docker logs-f. Это название нашего контейнера. И теперь мы увидели те же логи, которые мы видели до этого, когда сделали docker run. Давайте теперь попробуем запустить наш docker образ. С каким-то определенным наименованием. Это делается вот так. Docker run. Iris model 1.0. Minus name. Назовем его test. Test1. А, не, sorry. With end. Почему он рукуется? А, нет. С<|id|>. Так, почему он рукуется? Docker run. Что он говорит? When I will start. Docker run. Minus t. Iris model 1.0. Так, вот. Нет, почему? Minus name. А, вот, да. Sorry. Давайте сделаем еще раз. Docker run. Minus name. Test номер 2. Мы запускаем указываемое название. Iris model 1.0. И сейчас смотрите. Мы там запустили нашу команду. И теперь проверим, какие у нас есть. Сейчас у нас несколько запущенных. Но, что классно, у нас есть название наших. Эта команда, это без разницы. Так, можем смотреть на имена. Мы сейчас с вами сделали запуски двух токер контейнеров, которые назвали test1 и test2. И условно сейчас у нас они все запущены. Теперь у меня вопрос. Есть ли у вас вопросы относительно того, что мы сделали? Потому что сейчас мы дальше будем переходить на multistage Docker. Понятно ли вам, что такое слои? И из чего состоит Docker? Из очень простых команд. И как Docker build и Docker run. А что значит контейнер запущен? Контейнер запущен? Это говорит типа его статус? Контейнер запущен это говорит... У него есть несколько там вообще состояний. Статус это exited. Это о том, что ваша команда выполнилась и она закончилась. А если контейнер запущен, это говорит о том, что ваш контейнер не закончил работу. И он сейчас работает. Типа запущен стоит. То есть он ранится и ждет пока до ранится, да? Да, не до ранится. Да, но есть очень важный момент. Я вам сейчас кое-что покажу. Docker run-d name name s3 s3 все s3 Так, здесь что за команды были выполнены? Docker run-d это говорит о том, что мы запускаем его на бэгграунде. И это значит, что иди — это значит интерактивный. Хотя можно было без него. Name мы указываем. И Iris model. Еще очень важный момент. Что мы можем сделать? Вы помните, что мы прописали в нашем Docker файле команду, чтобы он его должен был выполнить? А теперь давайте попробуем зайти внутрь нашего Docker контейнера во время запуска. Мы можем условно перечеркнуть команду CND за счет вот такой очень простой вещи. Что он говорит? Docker run-d Не обязательно minus d. Docker run-name s4 название нашего образа 1.0 Мы добавляем ему такую команду, как pin bash. Кажется, так не было. Алина? Почему мне позволят не дойти? А, да, вот. Давай сейчас я все это выключу. Admiring Fermi. Stop setting check. Stop. Извиняюсь, меня слышно, да? Да, да. Насколько я помню, он не run, а execution. Не, да, сейчас мы его запустили. Да, я сейчас на него хочу зайти. Так, ну ладно. Сейчас я просто хочу выключить все остальные Docker, чтобы они не мешали. Docker stop s6. Stop. Stop. Stop. Stop. s6. Оха. Ну ладно. Restart. Там RL надо сделать, наверное. Не, я сейчас просто весь перезагружу. А вот теперь его можно удалить, да. Test номер четыре, test номер три, test номер два, test номер один. Docker admiring Fermi. Docker exciting gen. Docker run match. Почему мне не то? Все. Давайте теперь... Sorry, ребята. У меня просто очень много Docker создалось. Давайте попробуем запустить наш Docker словно без команды cmd. Это будет происходить таким образом. Docker run –d –... Мы запускаем его на бэкграунде в интерактивном формате. Называем его там name, name, name, name. Как бы назвать его? Name. Test ssh условно. Можно так сказать. Iris model 1.0. И в конце указываем команду, которую мы хотим. Мы смотрим на статус. Сейчас наш вот тот, который мы хотим. Мы смотрим на статус. Сейчас наш вот то, что мы в конце указали команду binbash. Это говорит нам, что через него можно зайти через именал. Он перечеркнул эту команду cmd python mainpy. И мы можем зайти через docker exec –et. Там название вашего docker-container. И команда, которую мы хотим восполнить. И все. Мы теперь находимся внутри нашего docker-container, который сейчас запущен. Можем даже проверить. Скорее всего, тут не будет рима. Там rect.xt. В нашем requirements.txt есть skykit-learn и numpy. И сейчас мы находимся внутри нашей команды. Давайте теперь попробуем здесь внутри... Мы сами можем зайти внутрь docker-container и запустить в нашу команду, которую хотим. Python, mainpy. И все. Как мы видим, внутри нашего docker-container у нас получилось его запустить. У вас есть вопросы теперь? Вы, получается, к контейнеру через SSH подключились? Это не совсем SSH. Условно... Да, да. Типа как SSH. Можно так назвать. Можно же сказать, что это виртуальная машина что-либо? Созданная. Смотрите. Сейчас, да. Это мы сделали. Это не совсем виртуальная машина. Это, по идее, виртуальная область внутри вашей операционной системы, которая повторяет, условно, какие-то определенные команды. И сейчас мы изолировали эту область. Запустили... Точнее, создали некий набор команд, который создал нам эту область, изолируя ее. И сейчас через команду docker-exec... Условно, мы... Когда изолировали, это значит, мы ее запустили. Она, условно, запущена в нашей операционной системе. И за счет docker-exec у нас получилось зайти внутрь этой изолированной области. И, условно, мы запустили эту команду. Типа, которую мы только что сделали. Потом мы импай. Мы запустили внутри нашего docker-контейнера. Но никак не повлияли на нашу хостовую систему. Сейчас есть вопросы? Мы сейчас будем переходить на практику lesson 2. А вот... А вот эти CUDA, Conda, чем они тогда будут отличаться от docker-а? Или они... Будто все по одному и тому же принципу работают. В каком смысле? Я просто вопроса не понял. А чем отличаются CUDA, Conda, от docker-а? Они... К примеру, у меня на линуксе Conda стоит, но... От docker-а я особо часто не пользовался. И у меня на Conda разные environments для каждой версии питона. Если в docker-е точно так же можно сделать. А чем они тогда отличатся? Смотри. Во-первых, CUDA это отдельная тема. Насчет... Здесь, условно, у тебя на питоне есть несколько virtual environments. Ну, условно, там... Conda nv1 и Conda nv2, назовем так. Они работают условно... Типа... Как бы, типа, ответьте, чтобы я дальше в дебри не зашел. Ну, наверное, самым простым будет условно. У тебя только одна версия CUDA стоит или несколько? Только одна. Только одна, да? Давай представим ситуацию, что условно тебе нужен старый PayTorch, который работает только с версией CUDA 10. Ословно, да? А ты на своем компьютере... Тебе что будет проще? Начать переустанавливать программы, которые связаны с твоей CUDA, или можно будет просто запустить какой-то Docker... Создать Docker образ, в котором уже... Эта CUDA уже предустановлена, она уже сделана, тебе не установки парис, ты можешь команду там сделать. Вот и все. Это для изоляции. Для изоляции и для некого... Чтобы... Когда условно ты будешь... Когда работаешь с огромными проектами, позволить себе устанавливать на свой компьютер какие-то библиотеки, это очень большая ошибка, потому что нужно будет париться с тем... А представьте, что какой-то сервер, который работает с библиотекой, и для каждого них нужна определенная CUDA. А ставить несколько CUDA в сервер... Сервер — это самоубийство. Условно, ты можешь у себя что-то чинить через отбием права, да? Но ты можешь сломать другу или коллегии его работу, и вы будете сидеть париться над тем, чтобы установить вам нужную версию, которая и вам подойдет, и тому подойдет. А если бы, условно, каждый работал по своему конкурсу, и вы будете сидеть париться над тем, чтобы установить вам нужную версию, и если бы, условно, каждый работал по своему Docker environment, то таких проблем не было бы. Я смог ответить на вопрос? Да, все понятно. Спасибо, Шей. Еще у кого какие вопросы, Себят? Спросите, если у меня Windows, то я должен запускать через Ubuntu, да? Или я могу дальше запускать как вы? Если не ошибаюсь, ты установил уже VSL, да? Да, установил. Можешь просто запустить VSL, и там можно через Docker запускать все. Типа, прям один в один будет. Все хорошо. Продолжаем, да? Окей, ладно. Так. Создание образа, интерпретирование образа, работа закрывается. Окей. Смотрите, ребят, здесь еще в последних Docker появилась такая очень крутая фича, называется Multistage Docker Glitch. Это когда вы билдите ваш проект, ну, условно, ваш финальный образ, в несколько этапов. Зачем это нужно? Типа, сам основной вопрос. Представьте, что у вас есть, типа, ваш базовый образ, в котором билдится огромное количество библиотек, условно, 20-30 библиотек. И когда эти библиотеки билдятся, они в конце... Типа, билд какой-то библиотеки в конце всегда сводится к тому, чтобы вы просто, условно, взяли какой-то файл, который дала, забилдил эта библиотека, и вы могли ее использовать. Но при этом для создания всех этих библиотек вы потратили, создали огромный Dockerfile, во-первых, в котором написали все. Хорошо, у вас получилось сделать там, создать, типа, полностью забилдить у себя в вашем Dockerfile, точнее, в вашем Docker-образе это 5-6 библиотек. Но результатом этих 5-6 библиотек будет каких-то 5-6 файлов, да? А все, что остальное вместе с этими установками этих библиотек пришло, вам не нужно. По этой причине у вас есть возможность в один этап, условно, сделать билд там 5-6 библиотек и просто передать результат на этих библиотек другому Dockerfile, который не проходил все эти этапы, вы просто словно поделились вашим результатом, чтобы вы могли дальше продолжить. Это очень удобно, когда есть в качестве примера, представьте, что есть какой-то проект, которому нужно много библиотек, и у вас есть базовый образ, в котором там билдится очень много библиотек, и есть такое понятие, как Dev и Production. На Dev у вас есть, вы хотите взять на основе этого база, но не хотите брать все, что в базе делается, и вы просто берете результат этого базы и работаете у себя в Dev, и этот Dev может отличаться от Production, и вы можете на несколько этапов разделять все эти вещи. Сейчас практика Lesson 2.3, они заключены... Спакутированы на то, чтобы мы могли понять, как будет работать MultiStage Docker. По-хорошему, я бы не хотел... Я бы просто вчера работал как раз таки с этим... Наверное, практика Lesson вам стоит поделать самим, а я хотел бы больше, наверное, рассказать про практику Lesson 3. Они, в принципе, чуть плюс-минус похожи. Давайте представим такую ситуацию. Вы хотите... Давайте я здесь... Stage – этап номер один. Это тренировать модель, подгрузить данный, претренировать модель, свалидировать ее, потом дальше сохранить модель. Этап номер два. Просто сделать предикт. У меня теперь к вам вопрос. Нужно ли на этапе номер два, условно, вам тренировать модель? Нужно ли вам подгружать данный? Нужно ли валидировать модель? Или заниматься всем тем, чтобы как раз таки подготовиться? Нет, да? И все библиотеки, которые были использованы для загрузки огромного датасета, который мог войнуть несколько гигабайт, для установки каких-то библиотек, которые могут натренировать машин. Нам это не надо. Нужно, чтобы при этапе номер один в конце вы просто какой-то модел Pickle передали в следующий этап. И как мы это сделаем? У нас есть два файла. У нас... О, Боже, как мне это бесит. Почему он просит меня установить это? Ладно. Да вон кнопка Ignore All. Ну все, вроде бы он пересел это делать. У нас есть файл ModelPy. У вас у всех есть этот файл? Что он делает? Что он делает? Из-за того, что у каждого человека на нашем уроке очень ограничены ресурсы в плане компьютера, я ограничил с очень маленьким датасетом, который... Что он делает? Он подгружает данные. Вот здесь. Условно представьте, что это огромный датасет, который весит несколько гигабайт. Делает TrainTestSplit, занимает какое-то определенное время. Создает некий pipeline, в котором он скейлит, потом обучает Support Vector Classifier, тренирует модель, потом в конце он делает... Safe нашей модели. Называется библиотека. Кстати, библиотека для того, чтобы сохранять веса... этих... как называется? В Skykit Learning называется JobLib. Она очень простая. Она просто сохраняет структуру вашей модели и просто сохраняет ее в локальных пайлентах. И она в конце сохранила вот этот ModelPipeline.JobLib. И в конце принтует ModelPipeline.Saved. А что делает Predict? Predict очень простой. Его задача просто подгрузить JobLib, сделать предсказание и там условно сказать... Точнее, сделать полноценное предсказание. У вас есть вопросы до этого этапа? Вроде бы все понятно, да? Да, да. Хорошо. Что у нас дальше происходит? Давайте посмотрим, из чего состоит наш Docker File. Наш Docker File состоит из двух частей. Это Multistage Docker. Как мы видим, когда мы сейчас будем весь этот Docker File Build, мы будем использовать это таким образом, что первым делом наш Docker создаст образ, в котором он... Устал мы его назвали As Trainer. Первым делом он создаст WorkDirUp, скопирует, установит библиотеки, потом скопирует File ModelPy в директорию нашего трейнера, потом выполнит команду Run Python ModelPy. И здесь очень важный момент. Почему мы не можем сделать CMD? Вот так, да? По той причине, потому что когда будет происходить Build, он не заметит эту команду... Почему он ругается? Ну ладно. Он не заметит эту команду, поэтому нам нужно выполнить это за счет Run. Условно отличие между Run и CMD в том, что Run происходит во время Build, CMD происходит во время Run нашего контейнера. И, условно, Stage №1 прошел. Мы полностью с вами прошли поэтапно весь этот момент. И наша команда, в которой находится внутри ModelPy, она забилдилась. И здесь результатом этапа №1 является File ModelPyPy. Как раз таки результатом всего вашего образа, который вы только что делали, это будет ModelPyPyJob. И как мы передаем его? Мы переходим на Stage №2. В чем же его в цюди? Вы просто берете... Опять же, смотрите, ребята, то, что у нас образ не отличается. Мы даже можем чуть-чуть липси взять, но пока я сейчас не хочу экспериментировать. Давайте останемся на этом. Мы все также создаем... Заметьте, сейчас ModelTraining существует как некий образ. Он создался, сделал ModelPy, и после этого мы создаем некий предиктор. Говорим, WorlderUp, все эти команды выполняем. И что происходит? Как мы с нашего трейнера вытаскиваем этот нужный файл? Мы просто берем, делаем копий, не с нашей локальной директории, не с хостовой системы, а с докер-образа, который создавался до этого. Мы берем ModelPyPyJob.ly и сохраняем в директории внутри нашего образа предиктора. Потом копируем наш предикт и просто говорим при запуске PythonPredictPy. Давайте попробуем это сделать. Переходим к терминалу. Давайте я его удалю, он мне не нужен. Мне нужно будет выполнить команду Docker Build-T, назовем его опять IrisModule2N. И все. Ой, там не нужен же куропей. Практика lesson3. Теперь смотрите, ребят. Сейчас у нас билдится трейнер. Как мы с вами можем заметить, слои трейнера билдятся, усломлен весь этот этап. Подождем пока он установит библиотеки. Можете на секунду ReadMe файл открыть? Какой именно? Тот, который в Practice Lesson 3. Вот этот? Да. Спасибо. Все. Сейчас он нам устанавливает... Еще один важный момент. Наш предиктор тоже параллельно работает. Он тоже... Как мы заметили, трейнер и предиктор одновременно дошли до этого этапа. И сейчас они должны синхронизироваться, потому что следующая команда это скопирование. Он не выполнит, пока не закончится, условно, стейдж номер один. Почему-то он долго устанавливает. Вот сейчас он должен закончить. Смотрите, ребят. Что у нас произошло? Вы заметили такой момент, что до определенного момента наш предиктор и трейнер одинаковы. Вот можем с самого начала заметить, что они шли друг с другом, что трейнер и предиктор устанавливали в библиотеке, что трейнер, что предиктор. И потом, чтобы запуститься в нашей команде в копии from trainer а по модулпайпланете по сохранению модели, он должен был подождать, пока Python ModelPy закончится. И стейдж номер один должен был закончить этап нашего файла внутри докера трейнера, точнее образа. И он должен был просто запустить Run Python Model. И только после этого наш предиктор смог получить результаты нашего трейнера в качестве модельки и потом скопировать предикт. И сейчас смотрите. У нас ничего не заранено. Но у нас есть образ. Давайте его зараним. Нет, можно просто name test. IrisModel. 2.0. И спускаем. И Predicted класс Setosa. Это говорит о том, что наш предик сработал. И у нас получилось сделать полностью предсказание. Мы залодили модель, которая была затренирована в стейже, который был заранее. И наш сэмпл, которому, условно, придумали, сделал Repredict. И в конце сделали предсказание. И еще раз давайте сделаем короткий резюме. Что мы прошли, зачем мы это сделали. Это было сделано ради того, чтобы мы поняли о том, что, условно, за счет таких мульти-стейджовых этапов можно до 10-15 стейджов идти, как вам удобно было. В чем суть? Это когда вы, условно, заранее должны были какую-то библиотеку забилдить. Вы ее забилдили, но вам не нужно все остальные файлы, которые рядом с ней. Вы просто передаете. Необязательно удалять. И все установки делать, чтобы эти файлы создались. А просто вы передаете файлы вашему следующему, условно, докеру-образу, который просто их возьмет, у себя заранит и будет с ними работать. В принципе, наверное, все. Уже прошел час. Давайте сделаем перемену на 5-7 минут. А пока можете задать вопросы, потому что последний практик в лессене 4 он будет чуточку сложновато, потому что мы пройдем docker-compose. Можете зайти в docker-файл. Да-да-да. И вот, мы сейчас же объясняли, только они в начале параллельно тренились, потом второй начал ждать первого. Просто по команду можете объяснить, до какой команды они одинаково шли вместе? И начиная с какой команды второй docker ждал первого? Вот здесь промтренер. Вплоть до этого этапа, условно, можем сказать, что они шли синхронизировано. Потому что у них, типа, основа одинакова. И они билдились. И когда нашему предиктору понадобился файл с тренера, ему пришлось подождать, пока, условно, тренер закончит, сохранит. И только после того, как мы... Типа, docker сам это понимает. Он понимает о том, что, типа, тренер закончил, и когда он заканчивает, он передает этот файл следующему stage'у, и stage просто подхватывает, и ему не нужно все остальное. Вот и все. Еще вопросы? И мне получилось задать вопрос? Да-да-да, спасибо. А вот этот run python modelpy, когда он этот ранит, 11 строка. Внутри что было, я забыл, modelpy, там была сама модель, да? То есть... Да, он же... У вас этот код же есть, да? Да-да-да, есть. А вы не подгрузили его? Нет. Потом надо делать. То есть, modelpy натренированная модель, да? А нет, это... То есть, она тренируется во время создания докера? Да-да-да. Ребята, я советую вам, когда мы проходим как lesson, открывать у себя код, чтобы вы могли просто смотреть, потому что мне нужно переходить между файлами, и не всегда вам удобно будет именно посмотреть через экран, можно так сказать. Да, modelpy просто выполняет команду, подгружает данные, делает разбивку через train.split, потом создает pipeline, в котором тренирует модель и сохраняет. И все. Результат modelpy. Все, я понял. Если бы это уже была натренированная модель, готовая, то процесс намного быстрее был бы, да, по ходу? Да-да-да. Ну просто я в качестве экзамплов вам показываю, как работает Docker в разных ситуациях, что не обязательно так делать. По идее, это было очень неудобно, разбивать огромный этап. Хотя это просто очень маленький экзампл. А представьте, что у вас есть, условно, своеобразный какой-то ваш софт, который вы обязательно должны билдить. И в первом этапе он может час или полчаса билдиться, и вы должны подождать, пока он закончится, чтобы условно запустить вашу команду. Еще какие вопросы, ребят? Это позволит нам удалить, например, если мы уже на втором этапе мобилитехи, которые использовались на первом этапе, которые уже больше не нужны. А зачем нам их удалять? Мы же потратили время, чтобы забилдить. Зачем нам их удалять? Очень важный момент, ребят. Образ нашего предиктора и образ нашего трейнера это два разных образа. Он просто передает файл друг от друга. И все. Я правильно понимаю, это два разных контейнера, да? Нет, нет, нет. Это не контейнеры. То, что сейчас происходило, когда мы делали билд, контейнера не было. Происходил только билд. Мы создавали образ. Это происходило внутри создания образа, и потом результат этого образа передался второму образу. Но пока мы не создавали контейнер, контейнер будет создаваться только из вот этого. И стейджа 2. Мы на основе него будем как раз это делать. Это получается области памяти, первая и вторая. Да, можно в таком формате понимать, что условно мы в этом кусочке памяти сделали билд, он создал какой-то результат, мы его передали, и во втором результате мы просто взяли результат первого, чтобы как-то с ним работать. А получается мы так экономим местное отец памяти? Да, да, все правильно. По идее, мульти стейдж был сделан как раз ради того, чтобы ваш финальный образ чуть-чуть, хотя бы меньше весел, чем Бог бы, условно. Потому что, например, если есть среди вас разработчики фронт-энда или бэк-энда на джебоскрипте, то есть такая очень неприятная тема, которая называется node-modules или разработчики Go, которые тоже делают определенные билды, и им не обязательно все библиотеки тащить вместе с проектом. Можно будет попробовать условно на первом стейдже все эти библиотеки забилдить и просто их результаты, ну типа их там эсошники, можно так сказать, или бины передать вашему второму образу, а все остальное просто оставить, потому что это мусор, который не нужен будет. Вот что делают мои файлы. Скажите, пожалуйста. Можете, пожалуйста, повторить вопрос и два вопроса было. Первый вопрос я не услышал, второй тоже, из-за того, что они одновременно были. Можно я спрашиваю, пожалуйста, model pipeline joplib, это получается, типа, йога, где храните сама модель, когда... Да-да-да, это условно файл, в котором вы сохранили веса вашей модели, вы натренировали ее, подготовили, она уже натренирована, ее не нужно тренировать, вы ее сохранили в каком-то определенном формате и просто передали. Я ответил на ваш вопрос, да? Окей, поняла, спасибо. И еще второй вопрос был, я просто не услышал, кто. Make file, что им нашлось? Make file это... Как бы объяснить? Я просто это делал для себя, чтобы было удобно запускать, но в итоге я ими не пользовался. Это условно набор команд, которые можно выполнять, типа, вот так. Могу вам показать. Мы сейчас не находимся, нам 11 лет нужно, практика lesson 3, и мы сейчас давайте с вами запустим. Условно это некий набор команд, в котором мы создали variable, называется imageName irisModel. У него есть команда build, run и clean и all. Давайте попробуем запустить make clean. Он нам удалит... make clean. Oh, боже. Он через нижний правый штурм сохранил. Да. John Doaker Remind irisModel 2.0 А, да. Это было в талантливом таблетке. А, да, у нас контейнер. Doaker stop. Doaker pass, Doaker stop, test. Окей. Условно то, что мы сейчас видим в нашем make файле, это make clean есть команда, run и make build. Вы можете создать условно команду outpear, которая просто скажет условно echo imageName make outpear. И вот он нам там сказал, я выполняю команду, и он просто сделал echo. Это условно набор инструкций, которые можно самому прописать, чтобы каждый раз терминали не вбивать. Только ради этого было сделано. Что будет, если просто написать make? Просто, как я знал, это из make файла, а не команда и make, то ли библиотеки, то ли что-то еще устанавливает. Да, да. Make, если я ошибаюсь, он должен выполнять сейчас all. А, нет, нет. А, нет. Make выполнит самую первую команду, а если мы сейчас сделаем make all, он сейчас будет поэтапно выполнять build, потом run. И вот он результат. А что тогда делает CMake? Чуть-чуть сложный вопрос, потому что я не смогу на него ответить просто за очень короткое время, но попытаюсь. CMake это команда, которая работает на основе CMake листа. Это тоже некий набор команд, которые можно выполнить. Обычно CMake очень часто используют для плюсовых, сихных проектов, чтобы можно было собирать огромные команды. Это набор команд, можно так сказать, чтобы вы могли забилдить ваш проект. Это builder, в идее проекта, если так сказать. Я просто сам CMake'ом пользуюсь и просто сказать, что это какой-то builder очень тяжело, потому что у него очень многофункциональная толза, которая позволяет делать очень много вещей. Но можно сказать, что это builder проектов, если так очень просто сказать. Спасибо большое. Мне просто в университете преподали CMake, но я не очень его хорошо понял. CMake это болезненная вещь. Извините, у меня тоже вопрос. Вы же сейчас, получается, имидж удалили, а почему он так быстро второй раз создался? Он где-то хранится в памяти после того, как мы его удалили? Наши слои не удаляются совсем. Они хранятся в кэше. Вот видите, то, что у меня закэшировано, он очень быстро создал. По той причине, потому что если сделать вот такую команду, Docker System.def, здесь есть такая вещь Build Cache. Это как раз, как он там предсохранил условно вот такую команду. Именно конкретно для этого образа. Для Python 3.9. Но если мы сделаем Docker System Pull Minus Op и все удали, и давайте попробуем теперь Make All. И сейчас он начнет все это шарманку и будет обратно. То есть он в кэше хранится, а потом мы можем его еще с кэша удалить. Да-да-да, все правильно. Спасибо. Еще какой-то вопрос был. Да, у меня вопрос возникал. Мы можем в Docker File только одну стажи засунуть? Только предыдущую, допустим, чтобы во время билдинга не тонировать модель и вообще насколько это правильно будет? Да, вы можете это сделать. Мы же в первом этапе так и делали. В Docker наш. У меня просто Docker File не запустился, поэтому я чуть-чуть... Понял. Да, первый проект, он это просто одностейджевый. Нам не обязательно там тренировать модель. Там она тренируется, но да. Можно условно с какой-то директорией, либо с хранилища, скачивать какую-то готовую модель, делать предсказания. С Docker вы можете делать все, что захотите. Он вообще не ограничен в этом плане. Вы можете... Ограничивается только фантазия самого разработчика. Что можно делать с Docker? Так, ладно. Еще какие вопросы, ребята? Сейчас просто начнется другая часть урока. Да, может, мне такой нестандартный вопрос. Вот Docker File мы в ручьем пишем всегда, или есть какие-то расширения, которые позволяют быстро слои все расписать? Да, насчет расширения не знаю. Есть некоторые помощники, типа для комплета, но нет. Docker File всегда нужно писать самому. Это как код, который вы обязательно должны писать. Это инструкции, чтобы вы могли все правильно сделать. За вас никто инструкцию не напишет. Но вы можете просто chargept попросить, сгенерировать какой-то Docker File в зависимости от каких-то ваших потребностей. Он это сделает, и потом вам придется его подкорректировать и уже смотреть. Просто чтобы работать с результатом, вам нужно понимать, что выполнять какая программа. Я ответил на ваш вопрос. Да, да, все отлично. Спасибо. OK, хорошо. Там на сайте Docker, кажется, есть для каждой программы стандартный какой-то Docker File. Да, там для Python, для Go, для Node.js, для каждого проекта есть определенные свои стандарты, по которым стоит писать. Да, можно на основе их писать. Но по-любому там не будет такого, чтобы просто его взять и запуститься сразу с одного пинка, там нужно будет по самому дописывать. Я его удалю. Начинаем, да? Следующий этап. Давайте теперь поговорим о таких вещах, как Docker Compose. Docker Compose это такая программа. Я кажется, вот, я кто-то открою, да. Docker Compose. Это такая программа, которая позволяет вам запускать, ну, условно, аркистрировать в композитор. У вас есть несколько, условно, есть селы, есть хор, есть скрипки, есть огромные инструменты. И вам нужно как раз этим аркестром дирижировать, аркестрировать огромным количеством инструментов. И что позволяет это сделать? Это позволяет как раз Docker Compose. У вас есть возможность запустить огромное количество приложений вместе с друг другом, которые будут работать в унисон. Давайте теперь мы попробуем с вами то, что мы сделали за счет мульти-стейджа. Давайте попробуем его разделить на несколько частей. Как это у нас получится? У нас это получится сделать, если условно у нас есть некоторый Docker File в нашем трейнере. Что он делает? Он берет там, опять здесь уже другой датасет, называется LoadVine, который там подгружается, делает очень простые вещи. Здесь мы используем random forest, красиво классифируем, делаем pipeline, fit, тренируем, потом сохраняем. В какой-то папке Shared, SharedModelPipeline. Пока можете не обращать внимания на название. Мы сохранили внутри нашего образа номер train, а образа train нашу модель. Заходим в предикт. Что же он делает? Ситуация такая же. Его задача очень простая. Нужно посмотреть. У него есть Shared. По какой-то диск вы заметили, что и в трейне есть Shared, и здесь есть Shared. Я сейчас расскажу о чем. Это говорит о том, что уже протренированная модель. И мы смотрим, появилась ли она. Тренировалась ли она. Этот while true будет работать до той поры, пока этот привик не найдет этот файл, не подгрузит его, и потом сделает предсказание. Теперь смотрите. Если мы с вами между двумя stages передавали за счет этого from, с одного этапа на другой, здесь мы поступим по-другому. Здесь у нас есть два docker-containers, train и predict. Train и predict запускаются одновременно. Train тренирует модель, predict просто предсказывает. Но перед тем, как предсказать, его задача не будет писаться отсюда. Он будет каждый 15 секунд проверять какой-то диск, какой-то фолдер, в котором якобы должна появиться модель. И как раз таки между этими двумя контейнерами есть shared folder, в котором они с друг другом разделяют, который есть и у него, и у другого. И этот трейнер сохраняет туда, predict берет оттуда. Но как это сделать условно для двумя docker-containers, это можно сделать через docker-compose. Вы создаете ваши сервисы. Первый наш сервис – trainer. Его задача context-train говорит о том, что ему нужно сделать build в папке train как раз таки. Потом мы говорим ему, что у тебя есть условно shared папка, а не shared, которая между ними стоит условно. Если не ошибаюсь, то, что первое указано, это хастовая система, а то, что второе – это которое внутри нашего контейнера. И оно в конце, не в конце, а когда забилдится наш трейнер, оно выполнит просто команду trainpy. Что же делает predictor? Predictor также билдит у себя в папке predict, который как раз таки здесь есть. Также shared в более шире и выполняет просто команду Python predictor. Перейдем, как сейчас мы с вами начнем весь этот процесс. Я бы хотел открыть два терминала. Можно пока вопрос задам? То есть при каждом запуске контейнера там с train и с predic там он будет сначала обучаться, потом выдавать определенный predic, да? То есть это будет по кругу? Нет, он не будет этого делать. По кругу он не будет ничего делать. Они оба одновременно сделаны. А мы будем работать с предиктом, и мы будем работать с предиктом, и мы будем работать с предиктом, и мы будем работать с предиктом, они оба одновременно запустятся. Они запустятся в тот момент, когда не, сначала каждый друг друга подождет, пока они забилдятся. Потом, после того, как билд произойдет, они запустятся. Наш train будет тренироваться, а наш predic будет смотреть на shared folder. Появилась ли там обученная модель. Если получше появилась, задача у train именно заканчивается. Он выключен, ну условно там, переходит от запущенного в законченный, и predic берет модельку, которая сохранилась в shared folder, наш trainer, подгружает, делает predic и заканчивается свою работу. Когда мы запустим этот docker-compose еще раз, он повторит это. Ну да, я общий смысл понял. А зачем тогда, чтобы он каждый раз обучался, не взяли просто один раз, затрейнить и просто использовать этот там файл для predic-то постоянно, например. Или это делается для того, чтобы использовать каждый раз разный датасет? Да. У вас есть сервис, который каждую неделю обучается. Скажем так, scoring-овая система для банков, у вас каждую неделю появляются новые клиенты, и ваша задача в каком-то этапе вы можете там заранее натренировать. Никто не запрещает. Это просто я показываю, как работает docker-compose. Это как один из примеров. Вы можете заранее натренировать, сохранить веса и просто запустить контейнер с этими весами. Никто не запрещает. Так можно делать. Я сейчас показываю вам экзамплы, как это один из примеров. Как можно попробовать работать с ним. Это очень маленькие примеры, потому что у нас очень ограниченное время и показывать огромные примеры, в которых можно тренировать большие датасеты, чтобы реально будет польза, nach alles Vitalize разделいて. Сейчас пользы бы уже нет. Н нам не нужно делить. С allein делаем. Просто lagчitz. чтобы resurrection в ehkä tama было некая консистенция вот вот и все понял я просто пытался ловить смысл именно в трене и предикте каждый раз чтобы при запуске докера нет смысла здесь именно как такового именно в плане очень глубокого смысла здесь сейчас просто я показываю как можно сделать вы можете по другому сделать я же как и говорил ранее вы типа докер ограничивается только воображением самого разработчика и ограниченности hardware вот и все так на чем остановились давайте теперь попробуем запустить мы заходим в наш практик lesson 4 докер compose app-d это типа если не ошибаюсь это уже комодом должны были они тут ссори ссори ссори мы сначала сделан докер композ билд сейчас мы с вами одновременно билдим и трейнер и предиктор они вместе с друг другом как-то происходит и сейчас происходит билд как вы можете заметить мы подождем пока они забилдятся сейчас мы выполнили команду билд что она сделала она в этом условно наборе команд дошло она сделала это круче просто билд мы сейчас зашли условно наш докер файл и дошли до этого этапа нашу команду 7 дникто не выполнил сейчас мы просто билдим наши образы которые с которыми нам сейчас нужно будет работать обычно билды докер файлов очень долгий процесс потому что именно для мл потому что они билдятся на основе очень тяжелых и ресурсом емких образов которые весит по несколько гигабайт и то что мы сейчас там билдинг 500 или 200 мегабайт это просто маленькая капля в море потому что у нас там маленький проект и нам делать как типа как таковых очень больших махинации не надо вот теперь смотрите ребят мы сейчас с вами создали два образа называется токер лэп практику лессен 4 это говорит о том что мы сейчас с вами создали два образа практикал с и трейнер и практикал с предиктор он если не ошибаюсь по дефолту докер композ берет наиминг основной наиминг папки в которой находится и потом название вашего сервиса и как мы видим эти сервисы названия совпадают да по тренер и предиктор на этом этапе они не шарят никакой фолдер они просто забил делись и теперь давайте сделаем докер композ а пинн с дик теперь а еще с должен успеть что он там сломался а он уже успел закончить он уже на трейлеровом модель и по этой причине он экзит а теперь давайте посмотрим наш предиктор я надеюсь успел он уже запредиктил как бы сделать правильно давайте мы с вами добавим смотрите ребят в нашем шерри фолдере появился файл потому что они друг другу шерри и трейн после того как закончил сохранил но как я понял сейчас не особо понятно что произошло потому что было очень быстро давайте удалим его он пока не нужен крайне мы с вами если не ошибаясь можно будет давайте какой-то slip seconds ну условно где-то 20 секунд добавим с липпинг сайт нас окей хорошо давайте теперь сделаем докер композ пилд окей теперь смотрите очень важный этап ребят сейчас кажется чтобы было понятно сверху это типа логи нашего трейнера снизу логи нашего предиктор ох нифига сел так был делаем докер композ да он у нас ничего не запущено имиджи докер композ от минус дим мы запустили наши докер контейнеры смотрите ребят ничего не происходит наш трейнер сейчас условно тренирует но точнее он спит условно подождем это 20 секунд страна спитер почему не запринтовал вот теперь посмотрите почему наш практикал лессен не сделал результат после того как он закончился а потому что а вот теперь да потому что наш предикт каждый после того как опрашивает условно он спит 15 секунд что сейчас произошло давайте вернемся мы одновременно создали два образа после того как мы создали эти образы мы их запустили образ образ трейнер он условно там тренировал 20 или 30 секунд какой-то определенный модель наш предиктор не мог запуститься пока не появилась там шерет модель ну модель которая подготовила типа наш трейнер и сейчас я за счет экзампла докер композа показал вам типа экземпляр как условно там два докер контейнера могут общаться друг другом типа этот может ждать пока пословно тот не тот не закончит процесс в принципе это все по докер композу теперь давайте к вопросам какие у вас вопрос по этому этапу ребят мне лично все понятно что нравится образа и контейнера образы контейнера я просто иногда как будто вы используете его не не не смотрите образ создается за счет докер файла типа когда вы делаете докер билд вы создаете образ когда вы делаете докер run вы запускаете этот образ и он превращается в контейн вот так кажется проще да еще как вы какие какие вопрос ребят просто нормально ли объяснил понятнее вам как работать с докер композа просто чтобы его более подробнее понять вам лучше самим с ним поэкспериментировать и условно потыкать с несколькими докер файлами поэкспериментировать вот это вот наверное самое правильное будет такой вопрос возник тогда будет ли какая-то дз именно по докеру отдельный или ну вот как у нас бывает же еженедельные дз по типу такого домашнее задание будет будет дано в понедельник вечером до этого мы пройдем с вами на следующем уроке мы будем проходить по стопи и чуть-чуть стремлит а потом в понедельник мы попробуем с вами типа целый энд тунн какой-то проект собрать который будет работать и домашнее задание скорее всего будет как раз таки вместе с докером связано ну что прям полноценное вот можно такие вопросы да конечно допустим у нас какой-то проект есть большой с большим количеством библиотек через докер можно сделать так чтобы мы каждый не каждый раз проходили этап ну подтягивание библиотек а чисто подтягивали в контейнер изменения которые мы сделали в коде да да конечно это через мультистрейч да делается нет нет не обязательно я кажется да забыл объяснить очень важный момент смотрите ребят давайте представим как раз к вашей ситуации то что мне сейчас будет проще сейчас кое-что сделать вам показать реальный пример сейчас андреонату сейчас покажу вам примерами так так так мне нужен был докер файл какой-нибудь классно смотрите это мне надо у нас есть некоторые некий докер файл да вот он большой это огромная партнер и условно представьте что мы билдим этот огромный проект всем видно да это такой один из примеров чтобы как раз ки ответить на тот вопрос типа нужно ли каждый раз его там перебил демида так так это какой-то северный проект да если не ошибаюсь это да какой-то там какой-то северный проект это реальный образ который но это не образ для продакшена я вам так скажу да да да я вообще просто я просто здесь для этого чтобы создать образ который можно тренировать модель чтобы не париться там с образами всякими если хотите и могу тоже поделиться он в принципе нормальный у него все есть так окей здесь это чтобы всем было комфортно видно так вроде все всем нормально видно да хорошо представим такую ситуацию у вас есть несколько здесь мы видим несколько слоев нашего докера не обращайте внимание типа на что здесь написано в этом они просто хочу объяснить что условно представьте что в конце результат этого проекта но типа этого до этой портяки это какая-то библиотека или какой-то там тренировка какой-то или там создание какого-то приложения и такой момент что условно если вы будете представьте что вы ваши библиотеки же меняться не будет и типа вы сейчас билдите каждый раз и условно копии там project project и вы если будете менять вот здесь и каждый раз делать билд этого докер файла все эти этапы каждый раз будет повторяться иметь в виду они каждый раз будут бегать они не будут кешироваться по той причине потому что вы в самом начале уже меняете условно слой и дальнейшие слои они не могут закешироваться условно чтобы облегчить и ответить на вопрос я к сожалению не помню кто задал достаточно будет в самом начале всегда типа сейчас будет некий там очень хороший пример после всех вот этих установок просто конца только но не в конце там в середине можно будет ваш код меня потому что вот эти команды они предельно быстрые и при себе все на меня получилось ответить на вопрос здесь именно как раз эти вы в самом начале билдите библиотеку билдите библиотеку и когда условно вы возвращаетесь к ней через день вам не обязательно будет все это переделать rebuild вам достаточно будет просто менять усимок от потому что все эти слои которые уже до до этого были были сделаны билдом они уже вполне закешированы на спину я смог ответить на вопрос да получается когда мы будем ребил дитя он будет сразу скопии да да да именно это просто самая первая ошибка наверное когда люди работают с докер файлом о том что они работают как раз со своим кодом добавляя сам вверху а библиотека устанавливает потом по этой причине иногда может происходить такое что вы меняете код и вам нужно переустанавливать библиотеки которую весит по полтора гигабайта еще раз каждый раз он это будет делать но это очень печально по этой причине лучше в конце это делать вот так давайте теперь вернемся к нашей лекции поговорим об nvidia docker к сожалению у меня сейчас у меня на компьютере это не получится встану эти показать вам не смогу вам придется с этим попариться самим но есть что вы можете мне написать как работает как работает видеокарта nvidia с докером есть специально утилита называется nvidia docker или nvidia container runtime в принципе одинаковый это вы за счет того что ваше приложение которое должно использовать куду оно находится внутри вашего контейнера и как это куда берет доступ видеокарте она как раз таки доступ видеокарте берет через nvidia docker и к nvidia container runtime типа условно некий проброс с вашего контейнера вашу хостовую систему ваш nvidia driver и он будет работать вместе с ним типа условно nvidia container runtime или nvidia docker это некий мостик между вашей куды и вашими библиотеками внутри вашего докера которые нужны там для fight or choo или там тезер фло без разницы с вашей видеокарты которая находится в вашей хостовой системе здесь есть вопросы нет окей хорошо просто когда мы будем работать с изображениями или там с любым другим проектом работа с кудой и работа с докером это очень такой важный процесс так следующее это си и сиди так принципе у нас еще есть минут 10 я хотел бы да помните я вам показывал цепочку когда у нас там мульти стейдж или докер композ все сиди это идеи и подословно перевод это continuous integration и continuous deployment это когда у вас есть возможность условно вы там у вас есть вас kitlab github там без разницы любой из таких платформ где вы можете сохранить ваш код и у вас есть возможность после какого-то определенного там комит сохранение создавать образ за счет этого типа в этом вы создали некий в какой-то платформе там называется есть специальная платформа которая называется это платформа которая позволяет типа когда условно вы сделали изменение в вашем основном приложении вы закомитили оно пришло там в централизированную систему и создал сборку условно уже сделала докер билд за вас вашего приложения и потом у него есть возможность как раз таки дальше этот образ отправить на развертывание как раз кисти ну если прям очень сугубо я об общем на разговаривать то во время сборки вся эта платформа делать некий докер билд во время развертывания он запускает докер ран вместе с остальными процессорами и если здесь прям очень так почему не могу пилд ну ладно ладно ссоре здесь нормально видно надеюсь до ребят да отлично видно а вот же внизу есть побоже как это поделитанский представьте что у вас есть ваш типа как построен некие continuous integration и continuous deployment когда у вас есть вы какой-то разработчик вы написали код закомитили его и в этот момент пошла сборка вы собрали какой-то пакет условно здесь видно потом этот пакет ну типа этот этот софт по или без разницы как это назвать его нужно доставить где нужно сделать докер условно 10 сайтов куда это нужно отправить или условно у вас есть ваш какая-то скоринговая система которую вы хотите обновить вы написали под обновили модель загрузили веса собрали сборку какой-то докер фо докер образ потом вы отправляете его на этап делили он деплоит деплоит каких-то серверах это все автоматизировано и в этот момент типа чем отличается от простык типа software development мл именно си и сиди о том то что ваша модель она всегда должна проходить в этапе перетренировок то что именно приходит новые данные и это при типа пришли нового данных что мы должны сделать мы должны повторить это только код вам писать не надо это все будет происходить автоматически новые данные пришли они подгрузились создалась новая сборка типа новая обновленная модель которая может быть чуть лучше может быть чуть хуже и все это уходит на как раз кино продакшн и мы все это мониторим в принципе это такой очень сугубо обобщенный вариант как из себя представляет процесс именно разработки и приложений был приложение все это может отличаться но если прям супер супер коротко и обобщенно то это присумим выглядеть так то что вы создали модель типа у вас появились данные вы создали модель ее обучили отправили на продакшн там сделали некоторые метрики получили фидбек и посмотрели что мы можем с этим делать получаем новые данные либо обновляем модель и обратно весь этот процесс повторяется это типа очень цикличный образ разработки где никогда нету остановки потому что вы можете еженедельно обучаться ежемесячно ежедневно можно даже типа запускать эти процессы что принципе ну типа очень удобно вот в принципе вопросы на этом принципе лекция наверное заканчивается теперь можно спеть вопросом ребят все понятно если вопросы по докеру если вопросы по инвиде докер или по практику лессену но мне кажется нам надо самим сначала поиграться с ней как-то попрактиковаться и в процессе практики возникнут какие-либо вопросы могут а так в принципе на в теории мне кажется мне ну лично для меня мне понятно окей хорошо предыдущий слайд предыдущие а кедра здесь да вот так и сейчас что делает но словно нет здесь это таком формате сказано то что после того как вы это в некой степени можно сказать что это образ так это ваш образ вашего приложения а получается продакшен водят да а да да да это автоматизированные условно конвейеры pipeline convey куда приходит условно ваш пакет ваше приложение и он автоматически может обновить или отправить на тестирование чтобы точно удостовериться то что это там этот пакет типа это приложение валидно оно проходит все тесты и можно обновиться типа перед тем как условно да доставлять до продакшен а у нас будет практика по си и сиди так к сожалению наверное нет чтобы сделать практику по си сиди для этого нужна целая инфраструктура к сожалению для всех сделать это будет очень сложно типа это просто представьте что для каждого нужно будет предоставить какой-то сервак где они могут это сделать типа на ваших компьютерах это к сожалению сделать нельзя хорошо тогда спасибо что как можно этому тогда научиться хотя бы не устраиваясь на работу с готовой инфраструктурой ну я имею в виду как это можно научиться как с этим можно научиться работать чтобы будущим на работе не опозориться не тут достаточно просто поправ правильно работать с докером этого будет принципе достаточно могу так сделать типа основа всегда это докер типа работа вместе с ним ну можно попробовать у себя локально установить можно хорошо поэкспериментировать докер композа что принципе тоже будет плюс минус что вы делаете си сиди вы тренируете модель обновляете его так так вот чтобы типа самому по практику к сожалению не подскорюсь сейчас может чуть позже вспомним могу отправить если больше что-то можно виртуальные машины создавать где-то дек это прод будет и через гитл это будет чуточку очень запарно и это нужно знать просто как это все делать там это бесплатно можно сделать но это будет очень сложно вот еще какие вопросы ребят у нас получается это последние первые последние лекции про докер да или будет еще нет следующие две лекции только из докера будем работать ну как типа на следующем уроке мы пройдем стрим лид но я надеюсь что мы его пройдем я хотя бы больше на права стапи рассказать где мы как раз таки будем оборачивать наш условно некий сервис создадим сервис который как раз таки будет условно мл сервис который будет отмечать может так сказать еще какие вопросы можно спросить вопрос такой если кто-то забил делал токер да какой-то контейнер у него был линукс а если я хочу запустить у меня можно запускать здесь очень важное допущение ты имеешь в виду что кто-то создал себе образ сохранил его и ты у себя на компьютер хочу его запустить такой вопрос да но у нас разные операционные системы нет проблем не должно быть подожди ты имеешь в виду кто-то создал образ не докер файл а вот именно прям образ куда-то запушил и ты его себе взял и ты сделал его просто докер антип и не бил делу себя такой же да ты имеешь это так или как нет она должен запуститься типа если кто-то делал на линуксе и у тебя под виндой тоже венкс он запустится спасибо могут быть проблемы с маком скорее всего потому что на маках есть типа есть архитектура x86 64 это на чем работать линукса и по системе линукс система под виндой у них есть конфликты с образами которые были сделаны на маке потому что там используется типа принцип arch 64 по этой причине не могут друг другу отличаться и скорее всего будут конфликты а если например он забил я потом могу же менять то что он забил делу если он сделал бил у него уже какой-то готовый образ вы можете подгрузить его бил и на основе сделать по базам его образ и да дальше как-то его виды изменяется типа в этом плане проблем нету типа вы можете его менять спасибо так в принципе наверное все на сегодня еще раз один вопрос если у вас вопросы по сегодняшней лекции если есть пожалуйста давайте не стесняйтесь потому что обычно происходит такое что и за такой вопрос и очень много людей молчат либо я очень плохо объясняю и никому не понятно или в принципе все легко просто такой момент окей даже ладно хорошо ребят давайте до субботы я тогда будем проходить создание приложений на фастапи и стрим лид утром суббота да будет 10 утра да в 10 утром будет все хорошо всем пока себя скажу но типа вот вы спросили я даже просто микро не успел включить я говорю я бы потестил с руками как раз до субботы потом уже с каким-то образом пришел хорошо хорошо окей все понятно тогда тогда посвятим первые 10 15 минут следующего урока как раз к докеру если у вас будут вопросы я на них попробую ответить все хорошо последний вопрос получается вот это пару недель мы получается будем изучать докер и еще что-то нет не пару недель если не ошибаюсь сегодняшняя лекция это докер следующая лекция это будет стрим лид и фастапи после этого будет лекция под названием n 20 project delivery когда мы прям полноценное мл проект соберем и условно попробуем его условно некой степени сделать delivery типа на вашем компьютере мы попробуем создать целый сервис типа каждый из вас там натренирует модель какой-то очень супер простецкую и мы попробуем у себя локально ее обернуть во что-то какой-то сервис и оно будет делать предсказание в зависимости от каких направленных документов типа например можно не обязательно один сэмпл отправлять как для предсказания можно попробовать даже документы ему скармливать и он на эти документы будет отвечать условно типа из этих ста человек они кто из них должник или кто из них не должник кто сколько должен такого рода можно будет делать вот типа мы прям полноценный а потом у вас будет две лекции если не ошибаюсь по продукт development потом уже начнется нлп если не ошибаюсь просто я могу сейчас посмотреть stop share сейчас одну минуту давайте посмотрю точно наш календарь чтобы точно сказать у вас кажется есть да силовос но там тема не на этом но там тема не написано который будет проходить на лекции если не ошибаюсь там обобщенно все да да 26 числа у нас будет как раз таки fast api и стрим лид 28 числа у нас будет n2n project delivery потом два урока будет вести артем 30 октября и 2 ноября будет продакт development и потом дальше уже будут две недели одна неделя будет project week и потом после про джет project уика будет demo week и потом только после этого это 18 ноября я сейчас это говорю по силам сможешь что-то измениться дальше у вас начнется нлп этот модуль например вместе с бибарасом вы закончили два модуля это классик мл и модулы в эвелейшен и до него я преподавал вам дата инжиниринг типа первого модуль и вот сейчас у меня модуль депломента вот принципе наверное все короче говоря примерно до конца этого года