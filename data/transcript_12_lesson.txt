 Ребят, всем привет! В принципе, наверное, можем начинать или еще подождем? Доброе утро! Доброе утро! Доброе утро! как давайте начнем давайте еще две минуты вы можете пожалуйста в группу хотя я что же могу писать да слышно сегодня чтобы проходить стремление так по идее целый урок будет про фастапи а следующий урок это ntwent project delivery я стремлито объясню нас на следующем уроке еще и мы попробуем обернуть и вашу прессе покажу как полноценное приложение делать мы сегодня это тоже пройдем для чего это нужно но фастапи скорее всего типа не скорее всего это объяснение чтобы можно было условно создать сразу же маленькое приложение которое можно выкатить в противодетов просто до этого когда условно как происходило когда хотели показать какой-то мгб очень простой которую можно было быстро обернуть и посмотреть модель как работает и ее выкатить в продакшн использовался фласс на питоне но потом создали другой проект называется фастапи который полностью закрыл надобность во фласске и не нужно было создавать целые приложения просто обернуть его в опишке и прям полноценно создать огромное приложение которое могло обрабатывать там очень большие запросы здесь больше наверное я хотел бы объяснить что такой фастапи и как можно на нем мы применить вот так в формате киеван тогда можно начинать так всем привет сейчас зашали экран сейчас экран видно да ну deputy минспеаши сейчас а dereg Не узнаем куда� Может 다음 времяwu:] есть второго В sends о чем мы сегодня поговорим мы сегодня поговорим в общем пастапи флазк и торнадо и еще там проведем очень хорошие практические уроки который по идее будет большинство большинство часть урока по этой причине у вас должен быть уже предустановлен докер и по-хорошему должен быть питом на компьютер надеюсь у всех есть да если у кого нет пока вы можете слушать лекции попробуйте установить все так следующие шо-то кафа стопи как как принципе рассказал за ранее это инструмент который позволяет создавать приложение которое основано на endpoint который может подключаться к бодиданных который может принципе делать весь функционал который происходит там на других бакет проектах точнее бекон библиотеки афпетона как типа джанго торнадо там флазк и так и так далее в том формате что чтобы быстро обернуть приложение которое будет там очень простым не простым функционалом с очень доступно формате за очень быстрое время типа тут вот как раз такие типа в этом и суть типа фастапи том то что за очень короткое время можно будет создать рабочие приложение которые реально может работать на продакшене по какой причине потому что разработчики фастапи они учли вообще все особенности то что сейчас питом очень сильно развивается сторону мл и чтобы можно было его спокойно прям из под коробки завести и туда положить условно вашу модель либо там несколько моделей чтобы они могли работать основным преимуществом фастапи является то что он в нем есть что он ассинхронный точнее может быть ассинхронным что-то вас не хроно и чуть позже расскажу он может быть ассинхронным у него есть возможности просмотра всех его там все его документации за счет свагер и это когда у вас есть вы заходите условно на ваш на ваше приложение и у него есть там некая колонка docs в которой полностью есть описание всех endpoint который вы сделали и в чем особенность еще также фастапи в том то что он максимально облегченный и на данный момент если не ошибаюсь это самая быстрая библиотека из всех имеющихся на питоне как раз для endpoint но быстрее чем джанго и фласски и далее и что-то кассихронный синхронно ассинк и синк они отличаются кардинально очень простым объяснением условно когда ваше приложение работает в одном потоке скажем так типа оно не запущено там на мультипоток а на запущено только на одном когда у вас синхронная когда у вас синхронное приложение условно вашем приложении который в одном потоке есть 2 3 endpoint если этот один endpoint в тот момент работает а страны косты и мы поинтом доступа нет они не будут работать теперь они будут заблокированы а синхронно это когда у вас есть возможность не блокировать функционал остальных там endpoint когда условно у вас работает один это очень удобно когда у вас приложение которым обращается огромное количество раз и здесь прям очень сильно спасает в этом плане и ювикорн это сервисное приложение очень сервисная библиотека самого питона который позволяет именно полноценный его запустить это условно замена простому запуску какого-то приложения типа питон там ваш название ваша скрипта точка пай ювикорн это сервисный интерфейс если до сервисный интерфейс который позволяет запустить вашего приложения его можно запускать на нескольких тредах указывать ему порты и хосты ну это как раз кито приложение который на продакшен запускается так далее но еще про сейчас до того как появился фастапи людям ну приходилось писать все это на фласке или на джанго или на торнадо джанго это прям полноценная библиотека которая позволяет создавать огромные в приложении на питоне типа это не маленькая библиотека которая поздно там чтобы сделать бы к это прям огромное многофункциональное с огромным количеством преимуществ с огромным количеством функциональных инъекций который позволяет там работать с разными базами данных с разными синхронить типа мидл веерами и это просто огромный мастодонт в этом плане пласт более облегченная версия джанго которая позволяет типа вот тоже в некой степени за очень флазк флазк и торнадо как раз таки они позволяют также также за очень короткое время создать сайт но здесь преимущественно том то что вы прям можете полноценное в приложении создавать фастапи к сожалению если не ошибаюсь нельзя не не дай сделать в приложении не нельзя присобачить к нему frontend по этой причине это вот типа некая корнева отличия между фастапи и флазка так дальше сейчас мы поговорим о том то что как типа про его установку как создавать простые приложения и там основные параметры там как как работать с самим флазком и в принципе как устроена у него структура его endpoint и попробуем посмотреть как оно подключается все эти параметры которые концепты параметры которые здесь описаны мы сейчас пройдем на практически на практически уроке где подробно остановимся про каждый из этих пунктов так надеюсь я вчера закидывал урок в класс ром там должен быть там если не ошибаюсь lesson точка зип в котором практически есть проект который мы сейчас будем делать перед тем как мы начнем а блин ссори ребят я походу очень сильно поспешил перед тем как начнем я хотел давайте посвятим где-то 5 10 минут если у вас вопросы по докеру как мы договорились на прошлом раке или мы продолжаем урок у вас вопросов нет по докеру не слышно да вопросов нет можно продолжать да да вопросов нет хорошо хорошо тогда перед тем как мы начнем практически в лекцию у всех ли у вас есть и тон и докер сейчас на компьютере у меня есть да да установленный хорошо так надеюсь у всех остальных установлены тогда продолжаем скачайте пожалуйста эту папку в ней будет папка называться lesson zip вот можно посмотреть скачайте пожалуйста это задание которые вот самое последнее в модуле машины наверняка у вас кажется приходит уведомление да потому что я залил туда или нет приходит приходит да окей хорошо скачайте отсюда материал вот этот lesson точка зип в нем есть несколько пиблиотекой несколько папок если что мы с ними будем работать так мл а нет нам basic уже сейчас смотрите мы мы остановимся как создавать приложение а у вас топи так реквест пас параметра или параметра она не спит а это все правильно вот хорошо сейчас у нас есть библиотека папка давайте просто скажем что это папка basic который есть полноценный проект я поправку которую сейчас условно можно будет запустить где-нибудь на сервере я дополнительно указал requirement все библиотеки которые вам нужно будет узнать в этом может просто там с питоном установить или сконда и там с пипом точнее нужно будет здесь в ритме я указал условно как вам нужно это будет сделать на конде но если у вас ана конда нет вы можете в принципе это сделать через ваш простой питон либо через virtual environment так все происходит таким образом что сейчас у меня уже все это предустановлено мы приходим в папку basic ok так и у нас в ритме если ошибайся даже написал как запуски про все правильно можно чуть-чуть пространство увеличить всего маленький а покейт сори еще вот так нормально ребят еще чуть-чуть но так да да вот и хорошо так сейчас я просто заранее подготовил уже environment не ничего устанавливать не надо но если вы сейчас это будете вместе со мной делать пожалуйста установите мы сейчас будем делать приложение на фастапе как происходит вообще создание приложений на фастапе давайте мы пока все это уберем нам это пока ничего не надо хотя не так можно оставить окей представь что у нас есть только hello world это простой так у меня вопрос надеюсь все понимают разницу между запросами get и пост все знакомы ли вы вообще с такими понятиями или вы вообще-то по первой слышите дата принципе знаем если есть ли человек который не знает что такое просто здесь очень важно что нужно ли мне объяснять просветить данному когда очень маленькое время объяснить типа что такой нпойнты я не знаю я впервые слышал а так и хорошо смотрите бакенде есть в общении бакенде запросах условно когда мы заходим на сайт когда он подгружается как раз такие идут такие процессы как подгрузка самого сайта и там в моменте когда вы кликаете там на какие-то действия либо заполняете форму и отправляете происходит очень ну типа разные действия там внутри за условно за ширму вашего сайта который куда возошли происходит огромное количество действий и чем типа есть самую там важный как раз такие запросы это типа get запрос есть get запрос и пост запрос get запрос этот когда вы условно пытаетесь получить у сайта какую-то определенную информацию или что-то получить вы отправляете условно через вашу строку на сайте какую-то определенную информацию и типа через get рекорд это можно будет получить пост запрос он существенно отличается он более многофункциональный это когда вы отправляете условно вместе на какой-то определенный сайт когда вы условно заполняете форму или там логин пароль это как пример и вы нажимаете submit вся эта информация которую вы только что ввели ее условно она вся оборачивается и превращается какой-то пленок там формат данных и отправляется на сайт в принципе это вот супер такой очень короткий клик без колебез на что такое гет запросы и пост запрос это как бы объяснить еще более более по простому но сейчас я вам покажу давайте мы сначала запустим наш сайт запускается он как указано в ритме файле там ювикорн мои а можно просто запустить и сейчас у вас выйдет такая информация о том что сейчас у вас приложение запущено и оно скажет вам на каком айпишнике и хостя на запущен на каком айпишнике и порту запущено здесь вот 127 0 0 1 это ваш локальный локал хост это то что у вас на компьютере происходит 8 тысяч вот давайте проверим теперь что происходит там стп 127 0 0 1 и 8 тысяч сейчас вы заметили что по обращению когда мы обратились к нему очень вот так смотрите просто типа 127 0 0 1 8 тысяч но ничего не произошло браузер нормально видно или мне его чуть увеличить иметь в виду ссылку адреса нормально так и хорошо что происходит у нас не получилось ничего взять потому что у нас в нашем приложении к сожалению мы типа не указали такой запрос давайте теперь попробуем дописать туда hello и у нас вышел hello world значит мы зашли условно на этот адрес 127 0 0 1 8 тысяч и обратились к нему дальше по дальше ссылки hello и это нам позволило получить информацию return hello world это говорит о том что мы сейчас когда вот так условно зашли на там я сейчас обновляю свою страницу это как что ни одни прям видно мы отправляем запрос на наше приложение и опрашиваем именно по этой ссылке пожалуйста условно дай мне информацию и как мы видим в логах нашего приложения он говорит о том что какой-то человек ну это условно я сейчас только что опрашивал приложение несколько раз давайте теперь проверим велиная ли это так сейчас она будет видно я сейчас обновляю свое приложение и мы сейчас опрашиваем точнее я обновляю сайт и мы сейчас опрашивал приложение запрос запрос как раз к и hello world и он нам сейчас отвечает это простой там где 3 коз которую можно будет сделать давайте теперь посмотрим так мне кажется пост пост да пост был покей пост можно можно быть показать окей теперь смотрите ребят сейчас мы с вами попробуем условно получить ту информацию которую мы сейчас отправим где три квеста как это получится у нас здесь есть модель смотрите модели внутри это не мл модели модели внутри там бэкенд приложение это чуть другое понятие это условно некая обертка точнее стандарт данных в котором можно будет использовать внутри приложение и приложение будет понимать в каком она формате какие у него там параметры есть например у нас есть базовая модель а это называется мы это подгрузили и у него есть три параметра это нейм прайс и изо все оно кстати оно опционально его не типа она обязательно может не быть типа по дефолту она будет но давайте теперь попробуем у нас есть условно уже какое-то приложение точнее какой-то приложение у нас есть один условно реквест который мы сейчас попробуем взять да и мы ему с ним поделимся информацией где отправим ему а это мой дей это условно мы его там укажем один два три без разницы и он нам в конце вернет типа информацию в таком формате типа айтом айде равно ки равно этому но сейчас смотрите очень важный момент киу мы сейчас ему передать не можем потому что мы передадим ему только айтом айди по этой причине киу он вернет нам как нам давайте проверим а это мы с вами вот как мы видим мы сейчас опросить опросили у нашего сайта а стп 127 001 8000 айтамс и 1 айдишник давайте поменяем его на 10 и он наверняка 10 но почему он возвращает киу но по той причине потому что мы передаем ему только айтом и по этой причине он просто его не поймет если ошибаюсь сейчас можем вот так сделать давайте вот так и сделаем если наш киу изнано то верни нам пожалуйста условно квадратичную там квадрат от нашего айтама ид и это киу будет киу будет равен например например а этом айди вложены перейдем в квадрат и сейчас мы должны перезапустить наше приложение мы перезапустили и сейчас мы вернули 10 и 100 все правильно давайте еще раз попробуем и 5 25 так у ки перед тем как мы дальше перейдем на другие части надеюсь здесь все понятно и по вопросов это не вызывает и пока как это происходит мы фастапи создали несколько инпоинтов которые мы сейчас будем опрашивать ребят вопрос вроде нет окей хорошо классно так и смотрите сейчас кстати и в чем еще особенное преимущество а я ж портит за двух дать сейчас мне нужно будет увеличить что мы сейчас видим у нашего фастапи есть уже готовые документации которые не нужно нам делать она уже сама все за нас сделала и сейчас у нас есть возможность сразу же здесь проверять как работают вообще наши эти как называется все наши инпоинты как мы видели hello это он вызывает функцию read hello как мы здесь видим давайте поговорим о ней да у нас есть функции типа endpoint hello как мы здесь указали у него есть своя функция read hello которая здесь говорится типа это red hello функция что же что здесь видно здесь показываются примерные ответы и точнее пол типа некое описание вашего endpoint на основе типа вашего приложения типа документация она уже готова давайте здесь что очень классный есть возможность проверять как раз таки как они работают давайте проверим третал экзекют что же произошло мы сейчас сделали тоже самое что до этого типа запускали до сейчас мы напрямую опрашиваем у нашего endpoint что же происходит здесь давайте пока я не буду объяснить что кукуру давайте спустимся на реквесты рел сейчас эта документация она просила наше приложение по реквест и релу hello и в ответ она получила вот такое типа message hello world но давайте попробуем чуть-чуть видоизменить это вернем типа посмотрим сможем ли мы это изменить hello world again and again например перезагрузим наше приложение обновим наш сайт мы на hello world попробуем третал экзекют экзекют и сейчас мы получили ответ по реквесте рел и получили да hello world again and again принципе здесь думаю все понятно да ok давайте теперь вернемся той функции которую мы делали нет это мы с вами проходили это и это это да ok третал сейчас смотрите здесь у нас есть возможность передать наш параметр функцию редайтом давайте вернемся что за функция это была это не надо эта функция вот это но сейчас смотрите мы сами внутри изменили q таким образом что какой бы мы q здесь не передавали оно будет меняться по этой причине давайте попробуем убрать этот функционал который сейчас нам не нужен ok хорошо передагрузим теперь давайте попробуем эту функцию сейчас мы проходим endpoint items item id у нее он вызывает функцию редайтом вот это сейчас мы работаем с этим и передадим ему условно там 10 а это мой день и куэрии назовем название куэрии hello там просто киев экзекют и сейчас смотрите что он нам вернул это результат response body типа он отправил в таким формате да ну здесь так себя давайте выберем и секрет вот сейчас как мы видим мы отправили вот такой request до этого я показывал то что есть возможность отправить вот в таком формате да чтобы дописать основу условно этот q куэрии мы добавляем ему запятую и говорим что q это hello и после этого после экзекюшена мы получаем ответ q item id равно 10 которому отправили и q там hello вот зачем вообще используется где типа самая распространенная это чтобы получить условно список людей условно из базы данных с такими айдишниками и можно присобачить информа еще дополнительные информации через q или другие параметры так давайте еще раз задам вопрос надеюсь понятно все что сейчас и делаю вопросов это не вызывает все очень просто и понятно если нет тогда давайте еще раз объясним да в принципе все хорошо теперь давайте спустимся к другую функцию у нас есть айтемс рит айтемс где мы сейчас попробуем отправить такие параметры как skip и limit но словно дай мне информацию в каком-то определенном регионе как мы видим когда мы зайдем на эту функцию он нам сейчас должен дать ответ таким образом типа должен вернуть айдишники типа айтемс это там айтемс айди фор аин рейн шкип и лимит это условно он нам должен вернуть типа давайте мы попробуем с вами это проверить что же нам должен вернуть айтемс давай-давай окей скип скажем равно 10 лимит равно они скип слишком много скип равно нулю лимит равно 10 и сейчас попробуем а равно и я вас сейчас там должны вернуть вот такой словно дикшн ри которым у каждого есть айтомы там айтем айди от нуля до 9 типа принципе он нам дал простой формы фор аин рейнш возвращаемся обратно к нашему приложению давай теперь проверим айтемс это наше теперь мы переходим к нему это айтемс default call уже кстати да здесь данные которые вы видите они по дефолту даны типа если сейчас мы просто попросим у него айтемс он нам должен там по дефолту вернуть давайте теперь проверим эквик ютин и он нам сейчас вернул как видно от нуля до 9 а что если нам нужно будет пропускать условно каждый второй до 20 execution и как мы видим в реквести тоже меняется мы передаем ему типа через запись через вопросительный знак параметр skip и я не знаю как это называется если честно мы говорим типа добавляем параметр и и говорим второй параметр и теперь мы смотрите ребят здесь мы скипнули два а нет это просто скип типа с какого начинать давайте проверим скипнуть условно там 18 и limit 20 за экзекютом он нам должен всего лишь два пара нет это не так он нам будет начинать там словно с 18 айдишника и дальше еще там 20 штук от него возьмет условно нам только один нужен экзекютин и да он нам вернут только один так здесь вопросов нет до дальше можно продолжать просто если есть вопросы задавать вообще без проблем у нас теперь есть возможность создать как раз кетет айтам это кажется у нас поздно условно типа крейт айтам сейчас мы смотрите ребят мы сейчас прошли все гет реквесты и сейчас мы приходим к пост запросу это когда вы оборачивать вашу информацию по какому-то формате чтобы передать но это повышает безопасность то что когда вы отправляете гетом как мы помните здесь проходили вы всю эту информацию в веру или даете что по идее это очень плохо для простых функций когда что-то нужно получить да это нормально но когда вы передаете информацию через ваш ерунда это вообще не безопасно по этой причине есть пост который более безопаснее и более ресурс такой мощный чем гет и что же он может мы передаем ему сразу айтам теперь заметьте очень важный момент мы ему переехали мы ему не говорим что такой айтам потому что заранее наш айтам уже был данным его мы задефинили некую модель у которого мы точно сказали что у него есть параметр на им который будет str price который будет float и из offer там он будет более нам но здесь очень важный момент если мы сейчас будем сами ломать говорить от рулять price там условно какой-то string значение он будет ломаться давайте сейчас посмотрим как работает функция пост стринг на им стринг прайсловно 500 и из offer уберем экзекют мы сейчас отправили вот условно такой запрос в реквестере вот такой и получили айтам нейн аутпир и 1500 но он нам не отправил информацию из offer давайте попробуем это изменить перезагрузим наши приложения перезагрузим этот сайт давайте попробуем уберем из афр он по дефолту по идее должен вернуть нам экзекют и как мы сейчас видим да он вернул нам ну а теперь давайте попробуем передать ему значение тру resetting из offer тру сейчас делаем экзекют и он нам сейчас вернул из offer тру теперь очень важный момент давайте попробуем поменять наш прайс вот так по идее он должен сломаться а нет он не сломался значит он а у него значить автоматически автоматически конверт во float а теперь попробуем другое сделать сейчас более экзекют да и он сказал что импут should be valid string это говорит о том что типа float его значение интежеру значение мы можем как стринг передавать потому что он автоматически передаст астер к сожалению не получится и мы только что сломали свою функцию а если мы обернем его условно кавычки из аэрзикете он нам должен вернуть все окей да наш айтам нейн правильную так вопросов нет с постом понятно тоже разница единственная разница то что мы реквестим класс они и рел ну не то что по идее да можно так сказать что вы оборачиваете вашу информацию не верил а в какой-то условно в какую-то сущность и передает ее вот да это вот ключевое значение типа отличия между ними получается оно само определяет именно какой класс какой именно пост да да да типа когда условно это происходит в какой-то форме где вы сейчас сразу показать но условно на каком-то где вы должны логин пароль вести вот с этой логин там пароль информации она не передается кетам это очень плохо потому что кто-то может перехватить это передается постом оно условно оборачивается и передается дальше вот так у нас мы можем это убрать теперь у нас есть рит юзер в принципе это уже не надо хитрый с кстати да мы можем сейчас проверить delayed response что же он делает это очень прикольная функция о том что и портаем давайте перейдем сюда эта функция она создав некий delay на время которое вы сказали и потом вернет вам ответ давайте посмотрим delayed response delay условно 5 секунд execute и сейчас он будет 5 секунд ждать ну сделать некий слеп и даст нам ответ response delayed by 5 seconds давайте сделаем 10 и дальше продолжим я сейчас типа 10 секунд заделал нашу функцию типа он дальше не позволил вернуться return и еще нужно будет подождать сейчас да и он сказал 10 секунд окей в принципе это все по базовым принципам типа самого fastp что очень просто создать пост опросы и гид запросы когда вы делаете там mvp или презентацию вашего проекта с вашей модельку этого более чем достаточно чтобы показать как она работает окей теперь мы переходим на мэйну в ралли теперь переходим на асиньк и сейчас я очень так кратко объясню чем же отличается синка то синка синк я пред pas세요 сNetナр У нас есть две функции. Типа RitaSync и ReadSync. Как я говорил ранее, когда у вас условно одна поточная приложение, но даже без разницы, как бы ни было, условно эти две функции запускаются одновременно. Типа в одном потоке. И кто-то сохраняет эти две функции, и он может запустить их в одном потоке. Типа в одном потоке. И кто-то захотел запустить функцию sync, и когда вы запускаете функцию sync, в тот же момент другой человек не может запустить функцию async. Ну типа запросить у него. По той причине, потому что будет заблокировано. Чем отличается? А что если мы сначала запустим async и потом sync? Тогда ваша функция sync отработается, не дождав до конца async. Как это можно проверить? Давайте мы сейчас с вами... Да, вот так сделаем. Даже 15 заблокируем. Мы сейчас сделаем простой... Так. Так, write out, execute. И сейчас идет loading. И write out, execute. И он уже... Мы получили ответ от sync, хотя async до сих пор происходит. И он заработал. Здесь суть в том, что наш sync блокирует, условно, все приложение, а async не блокирует. И это самое основное отличие между ними. В принципе, это, наверное, все, потому что мы сейчас дальше будем проходить, как работать с ML-моделью, и там будет понятно, как все это будет работать. Сейчас вопросов нет? Я показал ключевые отличия между ними? Ребят? Если у вас есть вопросы, пожалуйста, задавайте. Окей, тогда переходим дальше. В третье мы пройдем advanced. В нем есть readme, где вам нужно будет... Нужно будет... Есть два варианта. Вы можете, если у вас есть Anaconda, создать environment уже заранее. Или просто можете создать environment и полностью все это сделать. В принципе, у нас в основном проблем нет. В requirement все есть. Потом дальше мы залодим наше приложение и попробуем, как работать с базой данных. Так. Advanced. Main. Я, кстати, не объяснил, как работает UVCorn. UVCorn – это то, о чем мы говорили, сервис-министрфейс, который позволяет нашему приложению работать как целостное приложение. Main – это название вашего файла или библиотеки. Сейчас у нас это main.py, а app – это название вашего приложения. Потому что здесь мы запускаем, словно, main.app. И все, сейчас у нас запустилось. И о чем я хотел бы сейчас вам объяснить. Сейчас мы попробуем поработать с базы данных в SQLite. У нас есть таблица, которую мы создали не через base-model, а уже через SQL-model. У нее есть ID-шник, который там primary-k, и у него default-а нет, он сам автоматически будет инкрементироваться. У нас есть name, который... Required можно прописать? Они так required. Name – это str-field, age и secret-name. Потом здесь указанный функционал, чтобы подключиться к библиотеке SQLite. У нас сейчас, как вы видите, есть в папке advanced есть stdb. Это уже база данных вместе с таблицами. И автоматически вплоть до этого момента, когда ваш подзапускается, ваша связь с базой данных сделает таким образом, что это таблица нет, она ее уже создаст, но, к сожалению, она будет пустая. Сейчас мы можем проверить. Здесь, кажется, можно было бы отключаться SQLite. Сейчас проверим SQLite. Пусть услабливается. Вплоть до этого, допо условно, до 26 строчки кода, это все, что связано с базой данных, in FastAPI и база данных. Она создала базу данных, создала таблицу, если этой таблицы нет. Дальше происходят два очень важных... Когда ваше приложение запускается, именно Fastapish, оно запускает функцию create.db.entables, оно все это делает за вас. И дальше мы пройдем нескольким функциям. Это post и request. Переходим с http127.00. 18000 docs. У нас есть 4 функции. Post, которая создает нашего героя. GetHeroes. Мы берем героев, которые есть в нашей таблице. И GetHeroeID берем какого-то. И здесь берем Heroes. Мы его просто удаляем. Давайте теперь проверим, есть ли в моей базе данных Heroes. Что происходит, когда мы пытаемся взять всех героев? Вот это сессия, которая у нас здесь происходит. Это уже предефиненная функция, которую мы здесь заранее указали. Вот GetSession. Представьте, что этого параметра нет, оно автоматически всегда прогружается. Если вы хотите работать с базой данных. У вас есть какой-то offset и limit. С нашей базы данных. И сейчас наша функция GetHeroes должна вернуть всех героев до первых 100. Да, она должна вернуть 0,100. Мы берем Heroes. Здесь есть уже готовые наши offset и limit, которые мы здесь указали. Сессии не будет, потому что эта функция работает с базы данных. И он ее скрывает. А, еще что такое ListHero? Если это вот так посмотреть. Наша функция ReadHeroes, она принимает три параметра. Первый параметр, который мы уже заранее, когда наше приложение запускается, дает ему мысль нашу сессию. Сессия – это условно некая связь с базы данных. И мы здесь указываем типы данных. Это они оба интежеры. И что же нам должна вернуть? ReadHeroes должен нам вернуть какой-то List с героями. Давайте теперь проверим, как это будет работать. Поставили у нас базы данных. Передапускаем приложение. GetHeroes. Давайте проверим эту функцию. ExitHeroes. Это говорит о том, что сейчас наша база данных пустая. Давайте попробуем туда добавить. И вот BodyRequest. Из-за того, что у нас Get, мы передаем offset и limit. Давайте попробуем создать нашего героя. Все это спрячем сейчас пока что. У нас есть пост. Что же здесь происходит? В принципе, очень просто. Из-за того, что FastAPI имеет модальные реквесты, у него есть сразу возможность передавать... Помните, мы говорили, мы сразу класс. Нам не нужно каждого каста. Мы не можем передавать касты. Мы не можем передавать касты. Помните, мы говорили, мы сразу класс. Нам не нужно каждого параметра по отдельности передавать, потому что этот hero уже будет... Информация про нашего героя, о котором мы здесь указали, SQL Model, она одновременно одинакова так и для базы данных, так же, как и для вашего реквеста. Это говорит о том, что мы точно не пропадем с типизацией наших данных. У нас они 100% ляжут. И это очень удобно в том плане, что вам не нужно будет думать, что ваши базы данных это были интежером или постом, потому что вы уже на этапе, когда вы отправляете пост-реквест, вы 100%... Этот hero SQL Model нам полностью все это гарантирует. Хорошо, давайте проверим, как это происходит. Сейчас мы передаем в наш Create Hero таким образом, что мы передаем его нашего героя. В сессии, как мы ранее сказали, оно уже понятно. И в конце он нам возвращает наш класс, точнее, нашу сущность на основе того класса, который у нас есть. Все происходит очень просто. Мы session.add, мы добавляем его в сессию. session.add, мы добавляем его в базу данных, коммитим наш датасет и рефрешим полностью все таблицы. И он в конце нам возвращает рейтинг hero. Это особенности работы с... Это даже не особенности с SQLite. Это особенности работы с базы данных именно FastAP. И сейчас мы сейчас проверим. Write out. Давайте проверим. Передадим... ID-шник нам передавать, как было сказано, кажется, не обязательно, потому что он должен... DefaultNone. Давайте проверим. Попробуем передать ему без ID-шника. Name назовем Outpeer. Age 15, Secret Name. Aengineering. Execute. Это как выглядит пост-запрос. Как в Request сейчас происходит. Heroes у нас скрыта вся эта информация. Ну, типа Aburns. И сейчас мы получили responseBuddy. Age равен 15, ID равен 1, Name равен Outpeer, Secret Name равен Aengineering. Теперь давайте попробуем передать ему с ID-шником 1. И он сейчас нам должен сломаться, потому что уже есть такой чувак. И Internal Server Error. Мы сейчас здесь получили ошибку. О том, что такое уже есть. Но давайте попробуем отправить с ID-шником номер 2. Execute. И да, responseBuddy у нас есть. У нас получилось создание. Теперь давайте попробуем посмотреть на этих героев. Execute. Heroes. Read Heroes. И получили всех этих двух ребят. Мы теперь точно знаем, что у нас есть какой-то герой с ID-шником 1. И герой с ID-шником номер 2. Они, блин, от меня отличаются. Давайте еще третьего добавим. Oops. Heroes. WriteUp. Назовем его условно Data Science. NoSecretName. Ему будет 5 лет. ID-шник номер 3. Executing. Да, мы получили. Все нормально. И оп. Пытаемся прочитать наши героев. WriteUp. Execute. Да, мы получили нашего героя с ID-шником номер 3. Точнее, мы получили всех. Теперь мы знаем его ID-шник. Давайте теперь попробуем получить этого нашего героя. Как это произойдет? WriteOut. Сначала да. Давайте вернемся к функции. Add Heroes мы разобрались. Read Heroes. Вот Read Hero. Как это происходит? За счет того, что у нас уже есть сессия, которая за нас может делать все эти SQL-запросы, мы ему передаем сессию. Сессии мы должны получить с нашей таблицы героя, у которого HeroID равен ID-шнику, которую мы сейчас передаем. Что же нам дает эта функция Get? Нельзя это провалиться. Здесь происходит таким образом, что сессия, связь с базой данных, мы хотим получить сэмпл с таблицы Hero под ID-шником HeroID. Если мы не сможем найти этого HeroID, мы вернем ошибку, что HeroNotFound. Иначе мы вернем ему Hero. Давайте проверим. У нас есть ID-шник 0, и он должен вернуть ошибку. HeroNotFound. Execute ID-шник №1. И он нам вернул того чувака с ID-шником 1. А если 3, то да, тоже ID-шник №3. Так, это... Окей, да, в принципе все. И у нас есть еще последняя оставшаяся функция, потом можем создавать образ. Это функция Delete. Как вы можете заметить здесь, как определяется, что у вас это Post-запрос, Get-запрос или какие-то другие, это после app.delete. Такие функции есть еще несколько. Еще есть Put. Это функционал как раз-таки Request. И с ними можно будет, ну, типа, вы скорее всего самим нужно будет ознакомиться. Сейчас я просто про самое популярное хотела рассказать. Сейчас мы попробуем заделить нашего чувака. Первое дело, мы должны получить этого Hero. Вот, как здесь мы получили с нашей сессии нашего героя по ID-шнику. Если его не нашел, он навернув вернул вашу. Но из-за того, что он нашел, он не столкнулся с этой ошибкой. Мы говорим ему, удали нашего героя и закоммит сессию. Коммит — это очень важная тема в том плане, что вы точно синхронизируетесь в вашей базы данных, что данные, которые были на этапе Request, они точно положились в базу данных. Теперь мы можем провернуть ReturnOck. Давайте проверим. Хотим удалить условно ID-шник номер ноль. Такого чувака у нас нет. И он нам должен вернуть ошибку, что HeroNotFound. OK. Hero номер один, Execute. И он навернул Ock true. Давайте теперь проверим, реально ли удалились они. Executing наш ReadHero, когда мы читаем всех героев. И да, мы реально удалили чувака с ID-шника номер ноль. И он нам должен вернуть ошибку, что Hero номер один. А теперь можем ли мы создать, интересно, чувака с ID-шником номер один? По идее он нам должен позволить. Да, он нам позволил создать чувака с ID-шником номер один. Еще раз читаем все. И у нас есть чувак с ID-шником ID. В принципе, это все с базой данных по FastAP и все, что с ним связано. Дальше мы сейчас будем работать на целом ML-проекте. Если у вас вопросы, сейчас переменка на 5 минут, потом можем продолжить. Как сессия изнутри работает? Это типа connection open, потом connection close, сразу прописано или получается? Да-да-да. Когда вы работаете сессией, это сессия именно... Есть несколько библиотек. Я просто взял SQL Model. Это типа библиотека не FastAP, она особенно для... Сейчас, чтобы не соврать, SQL Model может работать. Давайте посмотрим. SQL Model Python Library. Это же не FastAP? Не FastAP. Это, в принципе, открытая библиотека, которая может работать. Да, она для FastAP была сделана, да. Прикольно. Да-да-да, это FastAP-шная библиотека. Условно у нас есть наша библиотека FastAP, есть библиотека SQL Model. Она, условно, закрывает все те вещи, которые связаны с тем, чтобы вы сами прописывали Select, сами прописывали Delete, сами закрывали connection с базы данных, сами его открывали, коммитили. И, типа, условно, он забирает это в свою абстракцию, и вам в некой степени не нужно париться насчет этой части. Типа, он закрывает все эти вопросы, и вам главное нужно, чтобы все те модели, которые вы прописывали, это очень важно, все те модели, которые вы прописывали, они были правильные. Типа, вы с ними правильные, если вы с ними будете правильно работать, то он с базами данных тоже будет правильно работать. Окей, поняла. А какие виды вот этих моделей бывают? Вот SQL Model, вы сказали, Base Model, еще, может, какие-то есть виды? Я, к сожалению, только с ними работал. Но есть, не ошибайся, есть другие модели. Чтобы условно с Oracle, не ошибайся, нужно связываться тоже, есть определенные, типа, Engin и с другими базами данных. Насчет них, к сожалению, я вам не могу сказать. Окей, поняла, спасибо. Так, теперь еще раз прощу. И до того, что мы сейчас, последняя наш... последняя сейчас урока, она будет связана с ML-ом и Docker-ом, у меня очень важный вопрос к тому, разобрались ли вы с Docker-ом. Если нет, то сейчас будет очень сложно. Вопросов нет, да? Окей. Так. Есть вопросы еще по каким-то темам, которые мы только что прошли? Вопросов вроде нет. Окей. А где вот хранится датабаза, которую мы создали? Даже вот здесь. Да, это SQLite, с ним очень просто законнектиться, и это просто текстовый файл, где хранится. В принципе, любая база данных, это тоже текстовый файл, только более там в красивом формате. В нашем случае мы просто взяли супер облегченную версию, с которой только что поработали. Спасибо. Так, сейчас мы будем проходить практика Work 4. Он будет более сложноват, потому что нам нужно будет в моменте тренировать модельку. Нужно будет делать предикт. И еще нужно будет сохранять модельки. После этого у нас будет практическое задание, где вы будете это делать сами. Там нужно будет чуть-чуть изменить нашу модель и сделать ее более advanced, можно так сказать. Можем начинать? Да, давайте. Хорошо. Последняя папка ML. Папка ML. Здесь есть Docker File, в котором мы уже указываем о том, что мы берем base spitan3.9.slip, обозначаем рабочую директорию app, копируем наш requirements, который здесь есть. Мы можем вот так сделать. Реклайрменс.xt. Потом устанавливаем все библиотеки, которые указаны в requirements. Потом копируем все в нашей директории app. Точка это говорит о том, что вы копируете отсюда туда, в этом контексте, почему так указано. Первая точка говорит о том, скопируем все, где находится Docker File в директорию app. В этом случае вот эта точка означает app, потому что она туда будет копироваться, потому что мы указали, что мы работаем в директории app. И дальше выполняем команду uvcorn app. А теперь смотрите, мы до этого указывали вот так. Почему так получилось? По той причине, потому что у нас есть наша директория app, точнее наша библиотека app, в которой есть функция main, и мы запускаем в нем приложение app. Типа, условно, если бы вот так было бы еще кизэ, то нужно было бы эту папку app куда-нибудь папку кизэ закидывать. Но пока не об этом. Есть еще, мы указываем host 0.000, это типа запустить на нашем компьютере, и с портом 8000. Здесь попортов нет, да? Можно название угдира переименовать, может быть, чтобы не было патаницы. Угдир ад, например, а что-то другое. Куда надо скопировать? А вы имеете в виду вот это? Спасибо. Так, workDir, fastP, application, не, так слишком. FastP, давайте назовем. Так нормально? Да, это супер. Так. Тогда этот app мне тоже переименовать, да, на всякий случай? Давайте мы его переименуем MyApp. Надеюсь, сейчас у меня ничего не полетит. Теперь вроде бы норм, да? Мы все разграничили. Надеюсь, моделях нет, там их нет. MyApp. Здесь, в принципе, все окей. Окей. С Docker-файлом понятно? Вопросов нет, да? Можно продолжать? Хорошо. Что же мы сегодня должны сделать? У нас есть наше приложение MyApp. Это полноценное fastP приложение, у которой есть два модуля. Это API и ML. Давайте мы спустимся в наше основное fastP приложение. Здесь оно создало некое приложение FastP, куда заинклудило роутер. Сейчас объясню, что такое роутер. Смотрите, когда вы создаете приложение, вам же не очень удобно будет, если все будет в одной папке. И для каждого, условно, типа API или типа модулей, условно, работа с баз данных, можем отдельно сделать, и у вас есть огромное приложение, где есть часть, которая работает с коллакскими моделями, и есть другая часть приложения, которая работает с английскими моделями. Условно это правильно, LLM. И они друг от друга очень жестко отличаются. И чтобы разграничить их, вы создаете роутер, который ведет в эту часть приложения, это отдельное приложение, которое внутри вашего, типа miniApp, и ведете в тоже miniApp, где работаете с английскими моделями. И здесь точно так же. У нас есть. Так, API. О боже, теперь все это, надеюсь, не сломается. MyAppAPI. Все правильно. Это вот, когда вы будете заходить на самую основную страницу, он вам скажет Халифорния, housing MLOP. Но давайте теперь посмотрим, что находится в этом роутере. Это в наш API, типа MyAppAPIEndpoints. Вот здесь уже чуть посложнее будет. Здесь у нас есть целое приложение. Так, вот здесь тоже MyApp. У него здесь есть базовый модель, типа PredictionInput, который мы заранее обозначили. А, мы еще говорим, что мы роутер. Мы не говорим, что мы приложение, мы говорим, что мы роутер. А, давайте я заранее тогда объясню модельку. Так легче будет, кажется, чтобы потом не возвращаться к ней. У нас есть ML часть модели. Что же она делает? Мы создали класс HousingModel, в котором пока наш pipeline 0, и мы обозначили то, что... А, почему? Типа суть приложения, что она должна делать? Наше приложение, по идее, в моменте, должно уметь... Мы должны запускать на нем тренировку. И если во время тренировки кто-то захочет сделать inference, типа predict этой модельки, то он должен дать ответ, что сейчас моделька тренируется, и пока я тебе ответ не могу дать. По этой причине мы создали параметр TrainingInProgress. Ну, еще обозначили название фьючеров. И теперь смотрим. Мы запускаем осихронную, чтобы не блокировать весь процесс, осихронную функцию DevTrain, где говорим количество estimator и random state, это для рандо-форес классифера, и мы обозначаем, что TrainingInProgress True это сделано ради того, чтобы... что сейчас идет этап тренировки. Подгружаем датасет XY, типа с Калифорния housing. Если не ошибаться, это датасет для этого, предсказания цен на квартиры. Создаем целый pipeline, в котором стандартизируем наши данные, создаем регрессор, у которого есть количество estimator, в котором мы дали, и random state 42. Разделяем наш датасет Xtrain, Ytrain, и Xtest, Ytest, потом фитим нашу модельку, читаем... ну там, считаем метрики, сейвим нашу модельку, отмечаем, что ourInProgress уже финишит, и возвращаем status success. И если что-то во время нашей тренировки случится что-то не так, мы вернем ему что? Типа TrainingFailed по какой-то определенной причине, потом сразу засетим то, что наш TrainingInProgress он такой. Это все, что по функции Training. Сейчас это мы не разговариваем про endpoint, а про модельки, как раз таки, нашей модельки, которая работает. Точнее, модельку, которую мы будем использовать. Дальше у нас есть predictSingle, который должен получить фичеры, которые есть, да? Вот. MadeInk, HouseH, Average Rooms, и он по информации получит и должен сделать предсказание. Но здесь, смотрите, если в случае, что наша текущая моделька тренируется, он должен нам вернуть что? Sorry, модель тренируется. Если модельки нету, а, кстати, я еще хотел предъять. Если наши модельки нету, то он скажет, что он не нашел. Если текущий pipeline нашего класса сейчас non, то он просто возьмет и подгрузит модель, которая сейчас есть. Но это только в том случае, если наш pipeline non, если мы делаем самый первый predict. То есть, мы уже сразу подгружаем наш класс, и он сразу подгружается и в память остается. Подгружаем наш data set и возвращаем ему предсказание. Вот и все. Это по предиксингу. PredicBatch — это мы ему отправляем целый data frame, который также посмотрит, ничего ли не подгрузилось. Так, здесь по модельке все понятно, ребята? Вопросов не вызывает? Вроде бы очень просто. Нет вопросов. Окей, хорошо. Теперь давайте вернемся к той части. Сейчас, как мы разговаривали заранее, что у нас есть два модуля. Первый модуль, который отвечает за тренировку prediction и ML-часть. Но у нас есть еще API, который должен получить доступ к этой модели. Мы приходим сюда. Первым делом мы обозначаем, что это раутер. Потом мы подгружаем наш housing-модуль, который мы только что обсуждали. Вот этот класс housing-модуль. Мы его подгрузили. И когда мы его подгрузили, у нас по дефолту pipeline none, и фичер-неймс уже обозначен. Теперь смотрите. Из-за того, что есть очень важный момент, что мы где-то можем профокапить с названием колонки, да, реально, это прям очень частое случае, по этой причине мы обозначаем целый класс, как раз-таки базовый модель нашего FastAPI, который точь-в-точь совпадает с endpoint и model. Как мы можем заметить, вот эти все, они точь-в-точь повторяют, один-в-один они должны быть. Потом еще мы же будем отправлять реквест о том, чтобы он сделал тренировку, а по этой причине создали тоже base-модель равного количества истиматоров в рандом статусе. Хорошо, какие у нас функции есть? У нас есть три основные функции. Давайте сначала мы его забилдим. ml Docker build-t myapp Ой. FastAPI application application О, нет, Docker не закончился. Sorry. OK. Сейчас он нам должен создать приложение на основе нашего Docker-файла. Давайте подождем. Если что, все эти библиотеки уже указаны в requirements.txt. Это значит, этой части можно париться, точнее, не нужно будет париться. И все. У нас сейчас можем проверить, какие у нас имиджи есть. И мы можем проверить, что у нас есть. У нас сейчас можем проверить, какие у нас имиджи есть. Сейчас, ладно, я ударю все это. И у нас есть только наше приложение, которое мы только что создали. Давайте теперь его запустим. Для запуска я здесь заранее подготовил readme, Docker run –p, а блабла. Смотрите, ребята, как работает приложение Fast API и вообще, в принципе, как бы сказать, любое backend приложение, которое находится внутри Docker. Когда вы находитесь внутри Docker, вы запускаете приложение с портом 8000, но вы запускаете это с портом 8000. Как получить доступ к этому Docker извне? Это получается только за счет того, что, когда вы запускаете ваш Docker, ваше приложение, то вы перекидываете порт на вашем компьютере, точнее, связываете, условно, байндите с портом, который внутри Fast API и условно их соединяете. Теперь давайте проверим. Это делается очень просто. Вы передаете параметры –p под порты 8000 равно 8000. Вы просто копируете его. Давайте его запустим. Docker run –p 8000. 8000. У нас Fast API и application 1.0. Сейчас мне бы его на бэкграунде запустить. Чтобы запустить его на бэкграунде, достаточно сделать Docker run –d и вот все. Docker 7000. Ну да, все, он закончил. Docker stop. Сейчас еще кое-что сделаем. Добавим здесь –d. И еще name, fast API, application, нет, не назовем его. Моя, словно название нашего Docker и application. Теперь запустил. Сейчас смотрите, ребята, что мы сделали. Мы запустили команду Docker run –d. Это чтобы это работало на бэкграунде. –p мы передаем ему порт. Название –myapp и мы запускаем наш Docker image. Как мы видим, мой Docker контейнер по стапи application 1.0, работал, запустил из себя внутри команду и, как мы видим, порты тоже перекинуты. Можем логи проверить в нашем приложении. И они будут здесь. Теперь самое важное. Мы должны переместиться теперь. Теперь мы зашли в документацию нашего приложения. Давайте еще раз. HTTP 127. Мы перенесем документацию. Видимо, у нас здесь есть... Ладно, эти сухие мэйны. У нас здесь есть четыре основных endpoint. Get, который мы в самом начале видели, он должен нам дать ответ CaliforniaHousingMLAP, который мы здесь указывали. Помните? У нас есть API, есть main. Мы получили вот это, потому что мы обратились просто... Его API... Мы ничего не добавляли. Но как обратиться теперь к другим? У нас есть API V1 train. API V1 train – это определенная стандартизация, которая будет в веществе. И это, наверное, самый простой, как правильно указывать название API, чтобы не путаться. Зато, когда вы создаете вторую версию, вы можете просто на видово перейти, и у вас не будет проблем. Вот, например, endpoint, который затриггерит нашу функцию в HousingML, нашего основного класса, чтобы он начал тренировку. Давайте посмотрим на его конструкцию. Endpoints, нам это больше не надо. TrainModule, что же здесь происходит? Мы получаем TrainingParams. Что такое TrainingParams? Это у нас количество истимитеров и все правильно получили, все параметры правильно переданы. Наша асинхронная функция, это очень важно здесь. Когда мы сейчас запустим процесс тренировки, мы попробуем сделать там попробуем запустить какой-то API. Давайте даже проверим. Router, Post, Check. Тоже сделаем у вас синхрон, чтобы он не выпадал из общего. Return, check. Ничего передавать ему не будем. Return, working, everything. Но здесь очень важный момент. Мы его просто сейчас так обновить не сможем. Нам нужно будет выключить myApp и нужно будет забилдить его еще раз, потому что мы изменили код. И как, кстати, помните, в прошлый раз мы объясняли, что если вы меняете код, то изменяемая часть должна быть всегда в конце. И по этой причине наш Docker быстро забилдился. Но что будет, если мы сделаем вот так? Он будет нам сейчас все это будет устанавливать. И если условно мы сейчас изменим код и еще раз захотим обновить, наш requirement, т.е. наш PIP install еще раз будет запускаться, потому что мы изменили слой, и этот слой уже не может с ним законнектиться. По этой причине это очень плохая практика. Docker file. Что же мы теперь должны сделать? Docker. А у нас уже есть команда. Проверяем, запустилось ли наше приложение. Да, все окей. Она запустилась. Обновляем, и у нас уже есть чек. Кстати, давайте попробуем еще для трейна добавить тысячи estimator, чтобы модель обучалась дольше. Давайте попробуем. Execute. Сейчас модель тренируется. И теперь мы проверим, реально ли заработает наш execution. И вот так. Значит, приложение сейчас работает. Почему оно не вернуло мне? Либо у меня сейчас... Так. Это очень странно. 1000 estimator. 1000 estimator. Это было очень большой ошибкой. Давайте заканцелим. Reset. Write out. Что там у нас с логами? Все нормально. 1000 estimator было очень большое ошибкой. Давайте это... Docker stop моя. И вот. И вот. И вот. Запустим. Нам этот чек больше не нужен. Давайте хотя бы модель натренируем. По идее, это должно было быть быстро. Вот, он вернул ответ. Success. Ну все, да. Моделька наша закончилась, тренировка произошла. И теперь мы можем попробовать сделать predict. Predict single. Write out. Мне кажется, был очень хороший экзампл. Давайте здесь типа 1, 5. Здесь 2 поставим. Reapplation 100. И нам должен вернуть какой-то ответ. Execute. Presumpti code array expecting. Где-то мы пропустили запятую. Execute. Ой. И нам пришел какой-то обрубленный prediction. Давай теперь зайдем внутрь endpoint, что-ли происходило в Async. Predict single. А, точнее, да, мы же это посмотрели. О том, что к нам приходит наш prediction input, который мы только что с вами сделали. Вот все вот это. Оно переходит в base model prediction input, который мы только что описывали. И... Так, так, так. prediction в ином случае он должен был... По идее, по-хорошему сейчас... И до того, что сейчас у нас уже моделька есть, давайте попробуем так сделать. Запустим train на 100. Execute. Пробуем сделать еще prediction в этот момент. А, мы забыли, конечно, что сделать. Да, точно. Dockerfile. Workers. Async. Как кажется, был параметр workers. Workers<|tr|>. 4. Stop. Okay. I can stop my app. Okay. Еще раз abildim. Так, okay, хорошо. Мы сейчас запускаем приложение на 4 потоках. Это то, что мы сделали. Так, вот, и вот. Так, ну, и вот. Так, ну, и вот. Так, ну, и вот. Так, ну, и вот. Так, ну, и вот. Мы сейчас запускаем приложение на 4 потоках. Это то, что мы сделали. Так, Docker. Что здесь? Ну, да. Хм. Так, вот здесь, я прочитаю, почему он так ругается. Docker Build. Application. Okay. Теперь. Остапи workers. Так, так, все правильно. Workers 4. 4 workers. Так, так. Да, все. Теперь у нас приложение запустилось на нескольких потоках. Теперь мы можем проверить. Первым делом запускаем нашу тренировку. 250. Execute и prediction. Execute. No trained model found. Это говорит о том, что мы сейчас только что запустили процесс тренировки. Он сейчас вот до сих пор идет, и мы сейчас пытаемся в моменте у него Execute и пока он говорит, что no trained model found. И вот сейчас он получил prediction. Это говорит о том, что у нас тренировка закончилась. Как мы здесь можем увидеть. И теперь давайте попробуем. Так, с тренировкой мы разобрались. С синглом мы разобрались. Теперь батчим. Батчим чуть-чуть посложнее, потому что нам нужно будет загрузить туда файл. У нас, кажется, был файл. Это вот такой сэмпл. Был в датафрейме. Как мы его отправим? Это будет происходить таким образом, что мы получим. А, кстати, еще одна особенность в ASTOPi. Можно просто сделать такую конструкцию, чтобы он мог взять файл, который получил. И мы подбрежем файл. Декодим этот sysv файл, который мы ему только что отправляем. После этого, если хоть одна из этих колонок, она будет отсутствовать в нашем сэмпле, то он сразу сломать скажет, что типа, фичеров нету. Это вот очень важный момент. После того, как он удостоялся, что с данными все нормально, он сделает prediction. И дальше отправит. В ином случае он просто нам вызовет ошибку. Давайте теперь мы попробуем. Мы его сейчас подгрузили. У нас только это есть. И execute. И мы получили ответ по всем prediction. У нас здесь три prediction. И в sample.csp тоже три данных. Теперь, ребята, пожалуйста, сейчас у нас осталось буквально 20 минут. Я хотел бы, чтобы мы попробовали изменить нашу модельку. А именно, заходим в камелку. И здесь нужно будет изменить, как-то улучшить нашу модельку. Можно попробовать добавить другой regressor. Или можно попробовать даже добавить grid search. Но я бы лучше, наверное, попробовал его поменять на какую-нибудь там более другую модельку. Или вообще попробовать усреднить результаты двух моделей. Создать может две модельки получится. Давайте сделаем так. Попробуем обучить другой regressor. Это первое. И давайте попробуем add grid search. Вопрос задания понятен, да? Да. В принципе, можно начинать. Можно вопрос? В предыдущей вы показывали, что в модели GED получается новая версия модельки. Когда мы запускаем GED, мы обращаемся к этой модели. И получается... Нет, нет. В каком языке? Когда мы хотим получить результат от этой модели. Вы сказали, получается, каждый раз, когда мы тренируем, получается новая версия модельки. Старая удаляется, и новая загружается. Он не версинирует. Нет, он не версинирует. Это можно сделать. Это было бы очень заморочно. Если мы будем запускать GED и будем обращаться, он не будет обращаться на старую версию? Вот именно. Сейчас наша модель не доработана. Сейчас происходит такой момент, что у нас pipeline... Можно добавить версионирование, он будет использовать старую модельку. Можно всегда подгружать модельку, он всегда будет самую новую подгружать. Здесь это можно убрать, потому что когда он уже один раз обучился и сделал одно предсказание, то он не будет подгружать. Это можно будет изменить. Как этот роутер работает? Это идентификатор этой модели получается? Нет, роутер никак не связан с ML-частью. Видите этот API? API — это, условно, часть нашего FastAP. Мы просто рутим все, условно, вот такие, когда на нашу приложение приходит API, он знает, роутит, создает путь в этот API. Условно, это типа направитель. Типа папка, условно. Да, да. Если можно добавить еще другую, V2, другой, MyApp 2.0, и... Да, да, можно будет так делать. Вы можете создавать многофункциональное приложение, чтобы он всегда подгружал модельку. Но сейчас модель недоработана, она очень слабая, нужно добавить research, и нужно будет сделать так, чтобы он всегда подгружал модельку и, типа, брал саму обновленную. Если можно, можно сделать даже версию неровную, но сейчас это будет заморочено. Можете начинать делать? Ну, вот, вот, вот. У вас, к сожалению, сейчас запустился train и нужно ждать. А, смотрите. Вот. То есть, эти запросы зависимы. Поэтому... Смотрите, когда вы запускаете вашу функцию train, он понимает, что сейчас идет training in progress. Типа, он определяет, Он определяет, что сейчас TrainingInProgress, какой-то там параметр Self. И когда вы пытаетесь присказать, он проверяет, типа TrainingInProgress или нет. OK, OK. Если false, он тебя возвращает. Если true, то stop. Да-да-да. Stop. Да, OK. Все понятно. Спасибо. Хотя давайте сейчас сделаем только одно. У нас, в принципе, не так много времени. Мы сейчас попробуем добавить research вот сюда. И попробуем его улучшить, нашу модель. То есть это наша модель. Вам же объясняют, что такое research, да, или нет? Точнее, вы проходили эту? Да. Да. Ну все. OK, OK. Все хорошо. Но мне кажется, есть некое-то недоработание. Но мне кажется, есть некая-то недоработка, потому что сейчас она может сломаться. Хотя давайте сейчас посмотрим. Возьмем какие-нибудь параметры. Но это... Нет, это другие параметры. OK, да. Что то мы уже добили shit, но вы~~ Мы уже выбрали. Ага. warmer так-так так вот нашу параметры вы сейчас делаете да ребят да ну все хорошо так значит принципе мы можем убрать скейлер он пока не нужен сейчас мы превратим утром на пласт-регрессор клосожStephestor это с ogniéquалию и и и и и и и и и и и и и и и и и и так сейчас давайте попробуем теперь мы добавили критерч сказали штамп айплайн зафить предиктался и предиктоке хорошо давайте попробуем теперь его запустить м м м м м м м а еще задание нужно обернуть этот докер компози а типа сейчас же мы каждый раз это стоп и всяк типа делаем такие действия давайте попробуем еще это его докер компози обернуть так м моя докер билд минус т какой-нибудь аплод минус м так и хорошо теперь докер доте иммедж с м м а ну давай просто запустим а м м м м м м м м м м м м теперь проверим скаем дот м м м о а м м м м м м м м м м м м м м д д д д д д д на не А, ребят, оказывается, есть некая ошибка. Притом очень важная. И до того, что мы сейчас запускаем на нескольких воркерах, я не знаю, почему сейчас приложение блокируется, но оно работает неправильно. А в чем же тут типа ошибка? Походу, я это пропустил. Потому что сейчас все происходит таким образом, что когда мы предиктим, он не понимает, что Training in Progress, потому что он сейчас дает ошибку, что Model not found, когда мы отправляем его предикт. Но хотя по факту он сейчас должен Training in Progress отдавать. А почему этого не происходит? По этому причине, потому что мы создали несколько воркеров, и сейчас на одном воркере у нас тренируется, условно. У нас есть несколько экземпляров этого housing module, условно можно так сказать. И из-за того, что у нас есть несколько экземпляров, по этой причине в одном из них тренировка идет, а в другой не понимает, что у того тренировка идет. И это происходит, потому что они на разных воркерах это работают. Сейчас нам главное дотренировать нашу модель через Grid Search, и потом это Aberdeen Docker Compose. Я чуть позже более обновленный код скину, в котором уберем этот косяк, и с ним вы можете еще чуть-чуть поработать, посмотреть. Грид Search что-то очень-очень долго пошел. Как у нас тут? Пойди много. Вы точно так же сделали, да? Ребят? А, вот. Fitting five faults for each condensator. 3000, не-не, слишком много. Давайте попробуем вот так сделать. Ладно, все, уберем. Это будет достаточно. Там будет слишком много операций, поэтому еще он очень долго будет тренироваться. Docker. Теперь, теперь, теперь. Docker. 5000. 8000. От. Окей. Давайте еще раз попробуем. Запустим тренировку. Try it out, execute. Тренировка пошла. Там 20, типа, 20 фитов будет примерно каждый. Ну, вроде норм пойдет. Сейчас мы должны быстрее тренироваться. А кто-нибудь сделал? У кого-нибудь, говорит, Search получился? А, вот да. О, ничего себе. Смотрите. Она вообще не обучилась. Показала такие результаты. Но это просто нужно будет больше времени. У нас train score вообще минусовой пошел. И test score тоже. Но, в принципе, ладно. Это нам нужно чуть-чуть подправить нашу модельку, увеличить ее параметры, и тогда она будет более-менее нормально обучиться. Давайте попробуем сделать execution. И мы получили какой-то результат. Хорошо. Теперь давайте попробуем обернуть это в Docker Compose. У кого-нибудь есть вопросы насчет, говорит, Search? И того, что мы только что сделали. Ребят? Нет вопросов? Нет? Нет, нет, нет. Окей, хорошо. Давайте теперь попробуем обернуть наше приложение в Docker Compose. Сейчас. Нам нужно будет создать здесь Docker Compose. Их я был. Сейчас. 8, 7, 8. Поступи. У нас будет происходить здесь арты, которые нам нужны. Мы будем... Окей. В принципе, команда нам не нужна. Команда нам не нужна. Org.bit есть. Но им не нужен. В принципе, все. Так. Docker Compose. Так, теперь мы собираем MyApp. И того у нас... Docker Compose. Атминзд. Ой. Так, теперь мы собираем MyApp. И того у нас... Docker Compose. Атминзд. Ой. Docker Compose. Атминзд. Ой, сори. Почему он говорит, что это неправильно? Marking values. Так. У нас же был здесь Docker Compose. А, блин. Очень ошибка была. Все теперь вот? Так, теперь давайте попробуем так сделать. Запустим Docker Compose. Пусти. И сейчас он нам будет билдить. Docker Logs. Какое название? У нас тоже какое название? И у нас также оно доступно. Title. Execution. И ладно, запустим. В принципе, на сегодня все. Исправленную версию я постараюсь отправить до понедельника. Но там, в принципе, можно будет еще самому чуть доработать и посмотреть. В понедельник мы с вами будем проходить стрим-лит. И попробуем прям целое веб-приложение сделать. В таком формате за счет стрим-лита. Ну, типа там будет полноценная модель. И целое веб-приложение, которое мы сделаем на стрим-лите. Так, моделька натренировалась. И сделаем предсказание. Окей. У кого какие вопросы? У нас тут еще есть пять минут. Можно еще с Batch-файла спросить? Да, да. Batch-файл, мне кажется, три строки данных отправили на запрос. Да, да, да. У меня вот вопрос такой. Если там очень много будет, там тысяча, десять, наверное, запросов. Типа на ночь отправили, ждем там эти предыдущие. Нет, нет. Ребят, смотрите. То, что я вам сейчас показал, это один из экзамплов, как это можно сделать. Но если, условно, десять тысяч, как это можно сделать предсказание? Просто FastAP, он не так сильно предназначен для ML-проекта. Тут больше, наверное, про изображение, про текст или про другие форматы. Думайте это в формате, то что... Огромный файл вы точно не можете отправить. Он либо в память не влезет, либо какая-то ошибка будет. Я вам показал просто экзампл, что модельки могут так работать, что у нас есть возможность их тренировать. Но по-хорошему тренируйтесь они в таком формате. Это просто для экзампла, чтобы вы поняли конструкцию. А так FastAP очень удобно, чтобы можно сделать очень простое приложение, которое может делать предсказание. Вот и все. Если у вас большой файл, и вы работаете с таким endpoint-ом, то, наверное, будет правильно самому делить на несколько кусков и отправлять и именно в формате итеративно подходить к этому вопросу. Мы точно знаем, что есть какой-то endpoint, который принимает какие-то файлы, и у вас есть файл из 10 тысяч строк, вы можете просто по 100 делить и отправлять каждую минуту. Точнее, ждать, пока окончится другой процесс, например. В таком формате можно сделать. У кого еще какие вопросы, ребята? У FastAP есть какой-то лимит на количество запросов, которые он может обрабатывать одновременно? Или нужно какие-то параметры поставить, чтобы… Да, у FastAP есть… Нет, смотрите, там есть… Можно просто зайти в FastAP в документацию. И там есть конфиги, которые прописываются так. Где они были? А, вот. Когда вы запускаете через uvCorn, вы можете… Все ограничится чисто в вашем компьютере, потому что это не просто файлы, это все файлы, которые можно использовать чисто в вашем компьютере, потому что вы через uvCorn можете конфигурировать определенные параметры, насколько огромные файлы можете принимать, сколько у вас может длиться тайм-аут, сколько у вас воркеров может быть, сколько… Все эти процессы можно прописывать. Но опять же, все это ограничивается вашим сервером. У него, к сожалению, не знаю, сколько там можно обрабатывать. Это все зависит от конфигурации, которая была сделана. И если у вас будет возможность обрабатывать там 10 тысяч, то почему нет? И это зависит от функционала. Например, если вы будете обрабатывать модельками, то это что-то по-другому будет. Я смог ответить на ваш вопрос? Да, да. Спасибо. Да. Окей. В принципе, это все можно выключать. Ребята, еще какие вопросы есть? Все, что нужно вам для лекции и, в принципе, для урока, оно уже загружено. Домашка будет в понедельник. Я до понедельника еще отправлю чуть исправленную версию именно с осинками и с воркерами. Так, в принципе, наверное, все. Спасибо. До встречи. До свидания. Вопросов нет, да? В следующей лекции у вас все было понятно и нормально? Да, все понятно. Окей, хорошо. Всем пока, ребят. Хороших уханых. Стоп, шевель. До свидания. Пока-пока.